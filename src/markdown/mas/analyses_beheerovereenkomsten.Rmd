---
title: "Invloed van beheerovereenkomsten op akkervogels"
author: "Ward Langeraert"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  chunk_output_type: console
bibliography: references.json
---

```{r setup, include=FALSE}
# renv
renv::restore()

# Set up
library(knitr)
library(here)
opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE)
opts_knit$set(root.dir = here())

# Conflicting packages
conflicted::conflicts_prefer(dplyr::filter)
conflicted::conflicts_prefer(dplyr::select)
conflicted::conflicts_prefer(dplyr::lag)
conflicted::conflicts_prefer(brms::ar)
conflicted::conflicts_prefer(brms::do_call)

# Packages
library(tidyverse)
library(INBOtheme)
library(gridExtra)
library(sf)
library(brms)
library(projpred)

# Cache
model_path <- "./src/markdown/mas/brms_models/"
cache_path <- "./src/markdown/mas/analyses_cache/"
projpred_path <- "./src/markdown/mas/projpred_cache/"
```

# Inlezen data

```{r}
data_path <- here("data", "processed")
mas_data_df <- read_csv(here(data_path, "MAS_data_full_2018_2022.csv"))
```

```{r}
design <- mas_data_df %>%
  distinct(plotnaam, regio, periode_in_jaar, jaar)

mas_data_sf <- st_as_sf(mas_data_df, coords = c("x_lambert", "y_lambert"), 
                        crs = 31370)

perimeters <- read_sf(
  here("data", "processed", "piloot_perimeters.gpkg"))
```

# Dataset structuur

Hoe ziet de dataset eruit?

```{r}
glimpse(mas_data_df)
```

We visualiseren ook de waarnemingen en kleuren hoeveel jaren het telpunt geteld is.

```{r}
visits_per_jaar <- mas_data_sf %>%
  st_drop_geometry() %>%
  group_by(plotnaam) %>%
  mutate(n_per_jaar = n_distinct(jaar)) %>%
  ungroup() %>%
  select(plotnaam, n_per_jaar) %>%
  distinct()

mas_data_sf %>%
  filter(regio == "De Moeren") %>%
  left_join(visits_per_jaar, by = join_by(plotnaam)) %>%
  ggplot() +
    geom_sf(data = perimeters %>% filter(Naam == "De Moeren"), 
            colour = "firebrick") +
    geom_sf(aes(colour = factor(n_per_jaar)), size = 0.5) +
    labs(title = "De Moeren", colour = "aantal jaren\ntelpunt geteld") +
    guides(colour = guide_legend(override.aes = list(size = 3)))
```

```{r}
mas_data_sf %>%
  filter(regio == "Oostelijke leemstreek") %>%
  left_join(visits_per_jaar, by = join_by(plotnaam)) %>%
  ggplot() +
    geom_sf(data = perimeters %>% filter(Naam == "Oostelijke leemstreek"), 
            colour = "firebrick") +
    geom_sf(aes(colour = factor(n_per_jaar)), size = 0.5) +
    labs(title = "Oostelijke leemstreek", 
         colour = "aantal jaren\ntelpunt geteld") +
    guides(colour = guide_legend(override.aes = list(size = 3)))
```

# Gele kwikstaart

## Data exploratie

We selecteren de data van de Gele kwikstaart met broedcode \> 0.
We sommeren de aantal per telcirkel, telperiode en jaar.
We voegen ook afwezigheden toe.

```{r}
# Presence data
gele_kwik_presences <- mas_data_df %>%
  filter(naam == "Gele Kwikstaart",
         wrntype > 0) %>%
  group_by(plotnaam, regio, periode_in_jaar, jaar) %>%
  summarise(aantal = sum(aantal),
            .groups = "drop")

# Add absences
gele_kwik_total <- design %>%
  left_join(gele_kwik_presences, 
            by = join_by(plotnaam, regio, periode_in_jaar, jaar)) %>%
  replace(is.na(.), 0) %>%
  arrange(plotnaam, periode_in_jaar, jaar)

# Add variables
gele_kwik_df1 <- gele_kwik_total %>%
  left_join(
    select(mas_data_df, plotnaam, regio, periode_in_jaar, jaar, status_teller,
    which(names(mas_data_df) == "n_predators"):length(names(mas_data_df))),
    by = join_by(plotnaam, regio, periode_in_jaar, jaar)) %>%
  distinct() %>%
  mutate(jaar.f = factor(jaar))
```

We herhalen enkele plots die we ook in `modelleeroefening_Gele_kwik.Rmd` maakten.

```{r}
gele_kwik_df1 %>%
  group_by(regio, jaar, periode_in_jaar, aantal) %>%
  summarise(n = n(), .groups = "drop_last") %>%
  ggplot(aes(x = aantal, y = n, fill = periode_in_jaar)) +
    geom_bar(stat = "identity", col = "black") +
    theme(panel.grid.minor.x = element_blank(),
          panel.grid.major.x = element_blank()) + 
    facet_wrap(jaar~regio, scales = "free") +
    labs(y = "", x = "Aantal broedparen Gele kwikstaart per plot") +
    theme(legend.position = c(1, 0),
          legend.justification = c(1, 0),
          legend.direction = "horizontal")
```

```{r}
gele_kwik_df1 %>%
  ggplot(aes(x = jaar, y = aantal, colour = periode_in_jaar)) +
  stat_sum(position = position_dodge(width = 0.5), alpha = 0.2) +
  stat_summary(fun.data = mean_cl_boot,
               position = position_dodge(width = 0.5),
               fatten = 4, shape = "square") +
  facet_wrap(~regio, scales = "free") +
  labs(y = "Aantal broedparen Gele kwikstaart per plot", x = "Telperiode") +
  theme(legend.position = "bottom")
```

```{r}
# Calculate zomergranen_hfdtlt2 as specified in 
# exploratie_verklarende_variabelen.rmd
gele_kwik_df <- gele_kwik_df1 %>%
  mutate(zomergranen_hfdtlt2 = rowSums(across(c(graangewassen_hfdtlt, 
                                               zomergranen_hfdtlt)))) %>%
  select(-c(graangewassen_hfdtlt, zomergranen_hfdtlt))

strat_vars <- c("plotnaam", "regio", "periode_in_jaar", "jaar", "jaar.f")
response_vars <- c("aantal")
pred_vars <- c("area_prop_sb",
               "area_prop_bo_overig",
               "landbouwinfrastructuur_hfdtlt",
               "grasland_hfdtlt",
               "aardappelen_hfdtlt",
               "wintergranen_hfdtlt",
               "bieten_hfdtlt",
               "mais_hfdtlt",
               "wortelgewassen_hfdtlt",
               "vlas_en_hennep_hfdtlt",
               "groententeelt_hfdtlt",
               "peulvruchten_hfdtlt",
               "meerjarige_fruitteelt_hfdtlt",
               "groenbemester_hfdtlt",
               "zomergranen_hfdtlt2",
               "zaden_hfdtlt", 
               "gewas_div_shannon",
               "perceel_cv_area",
               "inertie_sb",
               "inertie_overig",
               "openheid_waarde_1000",
               "openheid_klasse_300",
               "x_plot",
               "y_plot",
               "is_sbp",
               "sbp",
               "haag",
               "houtkant",
               "boom",
               "bomengroep",
               "bomenrij",
               "bosrand",
               "natuur_exp",
               "status_teller",
               "n_predators")
```

We zijn vooral geÃ¯nteresseerd hoe de aantallen zich verhouden tot de verklarende variabelen (en dit per jaar per regio).
Dit zijn: `r pred_vars`.

```{r}
gele_kwik_df_mod <- gele_kwik_df %>%
  select(all_of(c(response_vars, strat_vars, pred_vars))) %>%
  rowid_to_column("id")
```

```{r}
plot_scatter <- function(x, y = "aantal", df = gele_kwik_df_mod) {
  for (reg in unique(df$regio)) {
    p <- df %>%
      filter(regio == reg) %>%
      ggplot(aes(x = .data[[x]], y = .data[[y]])) +
        geom_point(aes(shape = periode_in_jaar)) +
        geom_smooth(formula = y ~ x, method = "lm", colour = "gold") +
        geom_smooth(method = "gam", colour = "firebrick") +
        facet_wrap(~jaar, scales = "free") +
        ggtitle(reg) +
        theme(legend.position = c(0.8, 0.2),
              legend.direction = "vertical")
    print(p)
  }
}
```

```{r}
continue_predvars1 <- gele_kwik_df_mod %>%
  select(where(is.numeric)) %>%
  names()
continue_predvars <- intersect(pred_vars, continue_predvars1)

for (var in continue_predvars) {
  plot_scatter(var)
}
```

## Model specificatie test 1

We vergelijken enkele simpele modellen:

-   welke distributies passen best? (1)
-   welke random effects moeten we toevoegen? (2)

### Modellen fitten (1)

We fitten vier modellen met verschillende verdelingsassumpties:

1.  Poisson
2.  Negative binomial
3.  Zero-inflated Poisson
4.  Zero-inflated Negative binomial

We beginnen met een simpel model met random effect voor telcirkel.

Beschouw $Y_{i}$ een observatie $i$ van een aantal broedparen in eenzelfde telcirkel $j$.
Deze observaties beschouwen we afhankelijk van de telperiode (dummy variabele $X_{\text{periode_in_jaar}}$), teljaar ($X_{\text{jaar}}$), regio ($X_{\text{regio}}$) en de oppervlakte proportie soortbeschermingsplannen binnen de telcirkel ($X_{\text{area_prop_sb}}$).
We voegen een interactie toe tussen regio en proportie sb zodat het effect kan verschillen per regio.
We voegen ten slotte een random effect toe van telcirkel $b_{1}$.
In een later stadium kunnen we testen of deze laatste noodzakelijk is en/of als er meer complexe correlatiestructuren moeten gespecifieerd worden (bv. autoregressive).

$$
g(\text{E}(Y_{ij})) = \beta_0 + \beta_{1}X_{\text{periode_in_jaar}, i} + \beta_{2}X_{jaar, i} + \beta_{3}X_{regio, i} + \beta_{4}X_{\text{area_prop_sb}, i} + \beta_{4}X_{regio, i} \times X_{\text{area_prop_sb}, i} + b_{1,j}
$$

```{r}
# MCMC parameters
nchains <- 3           # number of chains
niter <- 4000          # number of iterations (incl. burn-in)
burnin <- niter / 2    # number of initial samples to discard (burn-in)
nparallel <- nchains   # number of cores used for parallel computing

# Formula
form1 <- bf(aantal ~ periode_in_jaar + jaar.f + regio*area_prop_sb + 
            (1 | plotnaam))
```

```{r}
# 1. Poisson
sbp_gelekwik_pois1 <- 
  brm(formula = form1,
      data = gele_kwik_df_mod, 
      family = poisson(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_pois1"),
      file_refit = "on_change")

summary(sbp_gelekwik_pois1)
plot(sbp_gelekwik_pois1)

# 2. Negative binomial
sbp_gelekwik_negbin1 <- 
  brm(formula = form1,
      data = gele_kwik_df_mod, 
      family = negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_negbin1"),
      file_refit = "on_change")

summary(sbp_gelekwik_negbin1)
plot(sbp_gelekwik_negbin1)

# 3. Zero-inflated Poisson
sbp_gelekwik_ZIP1 <- 
  brm(formula = form1,
      data = gele_kwik_df_mod, 
      family = zero_inflated_poisson(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_ZIP1"),
      file_refit = "on_change")

summary(sbp_gelekwik_ZIP1)
plot(sbp_gelekwik_ZIP1)

# 4. Zero-inflated Negative binomial
sbp_gelekwik_ZINB1 <- 
  brm(formula = form1,
      data = gele_kwik_df_mod, 
      family = zero_inflated_negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_ZINB1"),
      file_refit = "on_change")

summary(sbp_gelekwik_ZINB1)
plot(sbp_gelekwik_ZINB1)
```

Convergentie voor alle modellen ok (scale reduction factors, trace plots, posterior density).

### Model selectie en fit (1)

We vergelijken de modellen gebruikmakend van 5-fold cross-validation (CV) (leave one out CV en WAIC berekenen niet mogelijk, *waarom?*).
Eerst worden de gegevens opgedeeld in $K$ delen (subsets) van gelijke (of zo goed mogelijk gelijke) grootte.
Vervolgens wordt het model $K$ keer gefit, waarbij telkens een van de $K$ subsets wordt weggelaten.
We stratificeren volgens regio.
Hierbij wordt er voor gezorgt dat relatieve frequenties per regio bij benadering behouden blijven.

```{r}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_pois1.rds"))) {
  fit_sbp_gelekwik_pois1 <- add_criterion(
    sbp_gelekwik_pois1, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_pois1"))
} else {
  fit_sbp_gelekwik_pois1 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_pois1.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_negbin1.rds"))) {
  fit_sbp_gelekwik_negbin1 <- add_criterion(
    sbp_gelekwik_negbin1, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_negbin1"))
} else {
  fit_sbp_gelekwik_negbin1 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_negbin1.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_ZIP1.rds"))) {
  fit_sbp_gelekwik_ZIP1 <- add_criterion(
    sbp_gelekwik_ZIP1, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_ZIP1"))
} else {
  fit_sbp_gelekwik_ZIP1 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_ZIP1.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_ZINB1.rds"))) {
  fit_sbp_gelekwik_ZINB1 <- add_criterion(
    sbp_gelekwik_ZINB1, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_ZINB1"))
} else {
  fit_sbp_gelekwik_ZINB1 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_ZINB1.rds"))
}
```

```{r}
models_dist <- data.frame(
  model = c("Poisson", 
            "Negative binomial",
            "Zero-inflated Poisson",
            "Zero-inflated Negative binomial"),
  naam =  c("fit_sbp_gelekwik_pois1", 
            "fit_sbp_gelekwik_negbin1",
            "fit_sbp_gelekwik_ZIP1",
            "fit_sbp_gelekwik_ZINB1")
  )

# Comparison among models
comparisons <- loo_compare(fit_sbp_gelekwik_pois1, 
                           fit_sbp_gelekwik_negbin1, 
                           fit_sbp_gelekwik_ZIP1, 
                           fit_sbp_gelekwik_ZINB1, 
                           criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                rownames_to_column("naam") %>% 
                full_join(models_dist, by = join_by(naam))

rbind(
  fit_sbp_gelekwik_pois1$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_negbin1$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_ZIP1$criteria$kfold$estimates[, "Estimate"], 
  fit_sbp_gelekwik_ZINB1$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = models_dist$model) %>%
  full_join(comparisons, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, naam, everything()) %>%
  arrange(desc(elpd_diff)) %>%
  kable(digits = 3)
```

De fit van de modellen verschilt niet veel van elkaar.
We besluiten dat het Poisson model toont het beste evenwicht tussen model parsimonie en model fit.
De posterior predictive check toont een goede fit van dit meest eenvoudige model.
We vergelijken de waargenomen tellingen met gesimuleerde tellingen van de posterior predictive distribution.

```{r}
pp_check(fit_sbp_gelekwik_pois1, type = "bars_grouped", ndraws = 100, 
         group = "regio", facet_args = list(ncol = 1, scales = "free_y"))
```

```{r}
pp_check(fit_sbp_gelekwik_pois1, type = "bars_grouped", ndraws = 100, 
         group = "jaar.f", facet_args = list(ncol = 1, scales = "free_y"))
```

### Resultaten (1)

We zien geen significant verschil in aantal broedvogels Gele kwikstaart met toenemende oppervlakte aan soortbeschermingsplannen.

De Moeren:

```{r}
hypothesis(fit_sbp_gelekwik_pois1,
           "area_prop_sb = 0")
```

Oostelijke leemstreek:

```{r}
hypothesis(fit_sbp_gelekwik_pois1,
           "area_prop_sb + regioOostelijkeleemstreek:area_prop_sb = 0")
```

Visueel:

```{r}
plot(conditional_effects(fit_sbp_gelekwik_pois1, 
                         effects = "area_prop_sb:regio"))
```

Cumulatief:

```{r}
get_hyp_estimates <- function(model, regio, perc_inc) {
  if (regio == "De Moeren") {
    hyp <- paste0("exp(area_prop_sb*", perc_inc, ") = 1")
    est_hyp <- hypothesis(model, hyp)
  } else {
    hyp <- paste0("exp(area_prop_sb*", perc_inc, 
                  " + regioOostelijkeleemstreek:area_prop_sb*", 
                  perc_inc, ") = 1")
    est_hyp <- hypothesis(model, hyp)
  }
 est_hyp$hypothesis[,2:5] %>%
   mutate(regio = regio,
          perc_inc = perc_inc)
}

increases <- seq(0, 1, 0.01)
out <- vector(mode = "list", length = length(increases) * 
         length(unique(gele_kwik_df_mod$regio)))

for (i in seq_along(unique(gele_kwik_df_mod$regio))) {
  reg <- unique(gele_kwik_df_mod$regio)[i]
  for (j in seq_along(increases)) {
    perc <- increases[j]
    index <- j + (length(increases) * (i - 1))
    out[[index]] <- get_hyp_estimates(fit_sbp_gelekwik_pois1, reg, perc)
  }
}

hyp_est_df <- do.call(rbind.data.frame, out)
```

```{r}
hyp_est_df %>%
  mutate(perc_inc = perc_inc * 100) %>%
  ggplot(aes(x = perc_inc, y = Estimate)) +
    geom_hline(yintercept = 0, colour = "grey", linetype = "dashed") +
    geom_line(colour = "black", linewidth = 1.2) +
    geom_ribbon(aes(ymin = CI.Lower, ymax = CI.Upper, fill = regio), alpha = 0.3) +
    facet_wrap(~regio) +
    theme(legend.position = "") +
    labs(x = "procent toename in oppervlakte soorbeschermingsplannen",
         y = "aantal keer meer Gele kwikstaarten")
```

### Conclusies (1)

Het Poisson model kan de data goed beschrijven.
We kijken nu welke random effecten we best toevoegen.

### Modellen fitten (2)

We fitten modellen met Poisson verdeling.
Het fixed effect gedeelte blijft hetzelfde als voordien:

$$
g(\text{E}(Y_{ij})) = \beta_0 + \beta_{1}X_{\text{periode_in_jaar}, i} + \beta_{2}X_{jaar, i} + \beta_{3}X_{regio, i} + \beta_{4}X_{\text{area_prop_sb}, i} + \beta_{4}X_{regio, i} \times X_{\text{area_prop_sb}, i}
$$

We beschouwen drie mogelijkheden voor de random effects:

1.  Geen random effecten
2.  Random intercept per telcirkel
3.  Autoregressive per jaar (orde 1)

```{r}
# id die telcirkels binnen telperiodes linkt (voor AR over jaren heen)
gele_kwik_df_modAR <- gele_kwik_df_mod %>%
  mutate(ar_id = paste(plotnaam, periode_in_jaar, sep = "_"))

# 1. Geen random effecten
sbp_gelekwik_pois0 <- 
  brm(formula = bf(aantal ~ periode_in_jaar + jaar.f + regio*area_prop_sb),
      data = gele_kwik_df_mod, 
      family = poisson(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_pois0"),
      file_refit = "on_change")

summary(sbp_gelekwik_pois0)
plot(sbp_gelekwik_pois0)

# 3. Autoregressive per jaar
sbp_gelekwik_pois2 <- 
  brm(formula = bf(aantal ~ periode_in_jaar + jaar.f + regio*area_prop_sb,
                   autocor = ~ ar(time = jaar, gr = ar_id, p = 1, cov = TRUE)),
      data = gele_kwik_df_modAR, 
      family = poisson(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel,
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_pois2"),
      file_refit = "on_change")

summary(sbp_gelekwik_pois2)
plot(sbp_gelekwik_pois2)
```

Convergentie voor alle modellen ok (scale reduction factors, trace plots, posterior density).

### Model selectie en fit (2)

We vergelijken de modellen gebruikmakend van 5-fold cross-validation.

```{r}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_pois0.rds"))) {
  fit_sbp_gelekwik_pois0 <- add_criterion(
    sbp_gelekwik_pois0, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_pois0"))
} else {
  fit_sbp_gelekwik_pois0 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_pois0.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_pois2.rds"))) {
  fit_sbp_gelekwik_pois2 <- add_criterion(
    sbp_gelekwik_pois2, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_pois2"))
} else {
  fit_sbp_gelekwik_pois2 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_pois2.rds"))
}
```

```{r}
models_random <- data.frame(
  model = c("Poisson geen random effects", 
           "Poisson random intercept",
           "Poisson AR"),
  naam = c("fit_sbp_gelekwik_pois0", 
           "fit_sbp_gelekwik_pois1",
           "fit_sbp_gelekwik_pois2")
  )

# Comparison among models
comparisons2 <- loo_compare(fit_sbp_gelekwik_pois0, 
                           fit_sbp_gelekwik_pois1, 
                           fit_sbp_gelekwik_pois2, 
                           criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                rownames_to_column("naam") %>% 
                full_join(models_random, by = join_by(naam))

rbind(
  fit_sbp_gelekwik_pois0$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_pois1$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_pois2$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = models_random$model) %>%
  full_join(comparisons2, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, naam, everything()) %>%
  arrange(desc(elpd_diff)) %>%
  kable(digits = 3)
```

Het eerdere model met random intercept geniet nog altijd de voorkeur.

### Conclusies (2)

Zowel per design als via k-fold validation lijkt het random intercept onze voorkeur te genieten.

### Conclusie

-   De Poisson verdeling kan gebruikt worden om de aantallen te modelleren
-   Er is een vrij groot verschil tussen beide regio's waardoor we quasi voor elke variabele een interactieterm zouden moeten toevoegen. We zouden best de analyses opsplitsen per gebied.
-   We willen nagaan of er een positief effect is van beschermingsmaatregelen. Zowel ter interpretatie als eenvoud van het model kan de `sbp` variabele misschien handiger zijn dan de `area_opp_sb` variabele.
-   De variabele `periode_in_jaar` vermoeilijkt de analyses (toevoegen van random effects). Het is allicht slimmer de aantallen per telcirkel per jaar te aggregeren. @klaassen2022 gebruiken voor gelijkaardige analyses *"het maximumaantal waargenomen broedparen (het hoogste aantal territoriale individuen van een soort tijdens Ã©Ã©n van de tellingen)"*.
-   We vermoeden ook dat er een duidelijker signaal zal vormen als we enkel de data van 2022 en 2023 bekijken.

## Model specificatie test 2

### Data preparatie

We nemen per telpunt per jaar het maximum aantal broedvogels over de telperiodes heen.
Enkel de variabele `n_predators` is afhankelijk per telperiode.
Hiervan nemen we het gemiddelde.

```{r}
gele_kwik_df_mod2 <- gele_kwik_df %>%
  select(all_of(c(response_vars, strat_vars, pred_vars))) %>%
  group_by(group_by(across(c(-periode_in_jaar, -aantal, -n_predators)))) %>%
  summarise(aantal = max(aantal),
            n_predators2 = mean(n_predators),
            .groups = "drop") %>%
  select(aantal, everything()) %>%
  rowid_to_column("id")
```

We selecteren data van 2022.

```{r}
gele_kwik_df2_2022 <- gele_kwik_df_mod2 %>%
  filter(jaar == 2022)
```

### Data exploratie

**sbp**

```{r}
gele_kwik_df2_2022 %>%
  mutate(sbp2 = paste(sbp, "sbp")) %>%
  ggplot(aes(x = aantal, fill = sbp)) +
    geom_bar() +
    facet_grid(regio~sbp2, scales = "free_y") +
    theme(legend.position = "") +
    labs(x = "aantal broedparen",
         y = "frequentie")
```

```{r}
gele_kwik_df2_2022 %>%
  mutate(sbp2 = paste(sbp, "sbp")) %>%
  ggplot(aes(x = sbp2, y = aantal, fill = sbp)) +
    geom_boxplot() +
    facet_wrap(~regio) +
    theme(legend.position = "") +
    labs(y = "aantal broedparen",
         x = "")
```

**area_prop_sb**

```{r}
gele_kwik_df2_2022 %>%
  ggplot(aes(x = area_prop_sb, y = aantal)) +
    geom_point() +
    geom_smooth(formula = y ~ x, method = "lm", colour = "gold") +
    geom_smooth(method = "gam", colour = "firebrick") +
    facet_wrap(~regio, scales = "free_x") +
    labs(y = "aantal broedparen")
```

**area_prop_bo_overig**

```{r}
gele_kwik_df2_2022 %>%
  ggplot(aes(x = area_prop_bo_overig, y = aantal)) +
    geom_point() +
    geom_smooth(formula = y ~ x, method = "lm", colour = "gold") +
    geom_smooth(method = "gam", colour = "firebrick") +
    facet_wrap(~regio, scales = "free_x") +
    labs(y = "aantal broedparen")
```

**area_prop_sb** + **area_prop_bo_overig**

```{r}
gele_kwik_df2_2022 %>%
  mutate(bo_sum = rowSums(across(c(area_prop_sb, area_prop_bo_overig)))) %>%
  ggplot(aes(x = bo_sum, y = aantal)) +
    geom_point() +
    geom_smooth(formula = y ~ x, method = "lm", colour = "gold") +
    geom_smooth(method = "gam", colour = "firebrick") +
    facet_wrap(~regio, scales = "free_x") +
    labs(y = "aantal broedparen")
```

### Modellen sbp

Fit modellen.

```{r}
form2 <- bf(aantal ~ sbp*regio)

# 1. Poisson
sbp_gelekwik_pois12 <- 
  brm(formula = form2,
      data = gele_kwik_df2_2022, 
      family = poisson(), 
      chains = nchains,
      warmup = burnin,
      iter = niter,
      cores = nparallel,
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_pois12"),
      file_refit = "on_change")

summary(sbp_gelekwik_pois12)
plot(sbp_gelekwik_pois12)

# 2. Negative binomial
sbp_gelekwik_negbin12 <- 
  brm(formula = form2,
      data = gele_kwik_df2_2022, 
      family = negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_negbin12"),
      file_refit = "on_change")

summary(sbp_gelekwik_negbin12)
plot(sbp_gelekwik_negbin12)

# 3. Zero-inflated Poisson
sbp_gelekwik_ZIP12 <- 
  brm(formula = form2,
      data = gele_kwik_df2_2022, 
      family = zero_inflated_poisson(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_ZIP12"),
      file_refit = "on_change")

summary(sbp_gelekwik_ZIP12)
plot(sbp_gelekwik_ZIP12)

# 4. Zero-inflated Negative binomial
sbp_gelekwik_ZINB12 <- 
  brm(formula = form2,
      data = gele_kwik_df2_2022, 
      family = zero_inflated_negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_ZINB12"),
      file_refit = "on_change")

summary(sbp_gelekwik_ZINB12)
plot(sbp_gelekwik_ZINB12)
```

Vergelijk modellen.

```{r}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_pois12.rds"))) {
  fit_sbp_gelekwik_pois12 <- add_criterion(
    sbp_gelekwik_pois12, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_pois12"))
} else {
  fit_sbp_gelekwik_pois12 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_pois12.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_negbin12.rds"))) {
  fit_sbp_gelekwik_negbin12 <- add_criterion(
    sbp_gelekwik_negbin12, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_negbin12"))
} else {
  fit_sbp_gelekwik_negbin12 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_negbin12.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_ZIP12.rds"))) {
  fit_sbp_gelekwik_ZIP12 <- add_criterion(
    sbp_gelekwik_ZIP12, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_ZIP12"))
} else {
  fit_sbp_gelekwik_ZIP12 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_ZIP12.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_ZINB12.rds"))) {
  fit_sbp_gelekwik_ZINB12 <- add_criterion(
    sbp_gelekwik_ZINB12, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_ZINB12"))
} else {
  fit_sbp_gelekwik_ZINB12 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_ZINB12.rds"))
}
```

```{r}
models_12 <- data.frame(
  model = c("Poisson", 
            "Negative binomial",
            "Zero-inflated Poisson",
            "Zero-inflated Negative binomial"),
  naam =  c("fit_sbp_gelekwik_pois12", 
            "fit_sbp_gelekwik_negbin12",
            "fit_sbp_gelekwik_ZIP12",
            "fit_sbp_gelekwik_ZINB12")
  )

# Comparison among models
comparisons12 <- loo_compare(fit_sbp_gelekwik_pois12, 
                           fit_sbp_gelekwik_negbin12, 
                           fit_sbp_gelekwik_ZIP12, 
                           fit_sbp_gelekwik_ZINB12, 
                           criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                rownames_to_column("naam") %>% 
                full_join(models_12, by = join_by(naam))

rbind(
  fit_sbp_gelekwik_pois12$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_negbin12$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_ZIP12$criteria$kfold$estimates[, "Estimate"], 
  fit_sbp_gelekwik_ZINB12$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = models_12$model) %>%
  full_join(comparisons12, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, naam, everything()) %>%
  arrange(desc(elpd_diff)) %>%
  kable(digits = 3)
```

Model fit.

```{r}
pp_check(fit_sbp_gelekwik_negbin12, type = "bars_grouped", ndraws = 100, 
         group = "regio", facet_args = list(ncol = 1, scales = "free_y"))
```

```{r}
pp_check(fit_sbp_gelekwik_negbin12, type = "bars_grouped", ndraws = 100, 
         group = "sbp", facet_args = list(ncol = 1, scales = "free_y"))
```

Resultaten.

De Moeren:

```{r}
hypothesis(fit_sbp_gelekwik_negbin12,
           "exp(sbpbuiten) = 1")
```

Oostelijke leemstreek:

```{r}
hypothesis(fit_sbp_gelekwik_negbin12,
           "exp(sbpbuiten + sbpbuiten:regioOostelijkeleemstreek) = 1")
```

Visueel:

```{r}
plot(conditional_effects(fit_sbp_gelekwik_negbin12, 
                         effects = "regio:sbp"))
```

### Model fitten area_prop_sb

Fit modellen.

```{r}
form3 <- bf(aantal ~ regio*area_prop_sb)

# 1. Poisson
sbp_gelekwik_pois13 <- 
  brm(formula = form3,
      data = gele_kwik_df2_2022, 
      family = poisson(), 
      chains = nchains,
      warmup = burnin,
      iter = niter,
      cores = nparallel,
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_pois13"),
      file_refit = "on_change")

summary(sbp_gelekwik_pois13)
plot(sbp_gelekwik_pois13)

# 2. Negative binomial
sbp_gelekwik_negbin13 <- 
  brm(formula = form3,
      data = gele_kwik_df2_2022, 
      family = negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_negbin13"),
      file_refit = "on_change")

summary(sbp_gelekwik_negbin13)
plot(sbp_gelekwik_negbin13)

# 3. Zero-inflated Poisson
sbp_gelekwik_ZIP13 <- 
  brm(formula = form3,
      data = gele_kwik_df2_2022, 
      family = zero_inflated_poisson(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_ZIP13"),
      file_refit = "on_change")

summary(sbp_gelekwik_ZIP13)
plot(sbp_gelekwik_ZIP13)

# 4. Zero-inflated Negative binomial
sbp_gelekwik_ZINB13 <- 
  brm(formula = form3,
      data = gele_kwik_df2_2022, 
      family = zero_inflated_negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr",
      file = paste0(model_path, "sbp_gelekwik_ZINB13"),
      file_refit = "on_change")

summary(sbp_gelekwik_ZINB13)
plot(sbp_gelekwik_ZINB13)
```

Vergelijk modellen.

```{r}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_pois13.rds"))) {
  fit_sbp_gelekwik_pois13 <- add_criterion(
    sbp_gelekwik_pois13, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_pois13"))
} else {
  fit_sbp_gelekwik_pois13 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_pois13.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_negbin13.rds"))) {
  fit_sbp_gelekwik_negbin13 <- add_criterion(
    sbp_gelekwik_negbin13, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_negbin13"))
} else {
  fit_sbp_gelekwik_negbin13 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_negbin13.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_ZIP13.rds"))) {
  fit_sbp_gelekwik_ZIP13 <- add_criterion(
    sbp_gelekwik_ZIP13, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_ZIP13"))
} else {
  fit_sbp_gelekwik_ZIP13 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_ZIP13.rds"))
}
if (!file.exists(paste0(model_path, "fit_sbp_gelekwik_ZINB13.rds"))) {
  fit_sbp_gelekwik_ZINB13 <- add_criterion(
    sbp_gelekwik_ZINB13, c("kfold"), K = 5, cores = 5,
    folds = "stratified", group = "regio", 
    file = paste0(model_path, "fit_sbp_gelekwik_ZINB13"))
} else {
  fit_sbp_gelekwik_ZINB13 <- readRDS(paste0(model_path, 
                                           "fit_sbp_gelekwik_ZINB13.rds"))
}
```

```{r}
models_13 <- data.frame(
  model = c("Poisson", 
            "Negative binomial",
            "Zero-inflated Poisson",
            "Zero-inflated Negative binomial"),
  naam =  c("fit_sbp_gelekwik_pois13", 
            "fit_sbp_gelekwik_negbin13",
            "fit_sbp_gelekwik_ZIP13",
            "fit_sbp_gelekwik_ZINB13")
  )

# Comparison among models
comparisons13 <- loo_compare(fit_sbp_gelekwik_pois13, 
                           fit_sbp_gelekwik_negbin13, 
                           fit_sbp_gelekwik_ZIP13, 
                           fit_sbp_gelekwik_ZINB13, 
                           criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                rownames_to_column("naam") %>% 
                full_join(models_13, by = join_by(naam))

rbind(
  fit_sbp_gelekwik_pois13$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_negbin13$criteria$kfold$estimates[, "Estimate"],
  fit_sbp_gelekwik_ZIP13$criteria$kfold$estimates[, "Estimate"], 
  fit_sbp_gelekwik_ZINB13$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = models_13$model) %>%
  full_join(comparisons13, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, naam, everything()) %>%
  arrange(desc(elpd_diff)) %>%
  kable(digits = 3)
```

Model fit.

```{r}
pp_check(fit_sbp_gelekwik_negbin13, type = "bars_grouped", ndraws = 100, 
         group = "regio", facet_args = list(ncol = 1, scales = "free_y"))
```

Resultaten.

De Moeren:

```{r}
hypothesis(fit_sbp_gelekwik_negbin13,
           "exp(area_prop_sb) = 1")
```

Oostelijke leemstreek:

```{r}
hypothesis(fit_sbp_gelekwik_negbin13,
           "exp(area_prop_sb + regioOostelijkeleemstreek:area_prop_sb) = 1")
```

Visueel:

```{r}
plot(conditional_effects(fit_sbp_gelekwik_negbin13, 
                         effects = "area_prop_sb:regio"))
```

```{r}
out <- vector(mode = "list", length = length(increases) * 
         length(unique(gele_kwik_df2_2022$regio)))

for (i in seq_along(unique(gele_kwik_df2_2022$regio))) {
  reg <- unique(gele_kwik_df2_2022$regio)[i]
  for (j in seq_along(increases)) {
    perc <- increases[j]
    index <- j + (length(increases) * (i - 1))
    out[[index]] <- get_hyp_estimates(fit_sbp_gelekwik_negbin13, reg, perc)
  }
}

hyp_est_df2 <- do.call(rbind.data.frame, out)
```

```{r}
hyp_est_df2 %>%
  mutate(perc_inc = perc_inc * 100) %>%
  ggplot(aes(x = perc_inc, y = Estimate)) +
    geom_hline(yintercept = 0, colour = "grey", linetype = "dashed") +
    geom_line(colour = "black", linewidth = 1.2) +
    geom_ribbon(aes(ymin = CI.Lower, ymax = CI.Upper, fill = regio), alpha = 0.3) +
    facet_wrap(~regio) +
    theme(legend.position = "") +
    labs(x = "procent toename in oppervlakte soorbeschermingsplannen",
         y = "aantal keer meer Gele kwikstaarten")
```

### Conclusie

De analyses en interpretatie zijn eenvoudiger dan voordien en de modellen lijken goed te fitten.
Ook zijn de resultaten min of meer in lijn met de verwachtingen.
Voor `area_prop_sb` in de Oostelijke leemstreek gaf de gam in de data-exploratie een meer flexibele curve aan.
We kunnen die variabele ook kunnen opdelen in klassen (bv. \< 0.1, 0.1 - 0.2, \> 0.2).
Er zijn wellicht ook minder data \> 0.2 (waardoor je ook minder zeker bent van het niet lineaire verband).
Nog een optie is de variabele sqrt transformeren.

```{r}
gele_kwik_df2_2022 %>%
  ggplot(aes(x = area_prop_sb)) +
    geom_histogram() +
    facet_wrap(~regio)
```

```{r}
test <- 
  brm(formula = bf(aantal ~ regio*area_prop_sb_cat),
      data = gele_kwik_df2_2022 %>%
        mutate(area_prop_sb_cat = case_when(
          area_prop_sb == 0 ~ "area_0",
          area_prop_sb < 0.1 ~ "area_<0.1",
          area_prop_sb <= 0.2 ~ "area_0.1-0.2",
          TRUE ~ "area_>0.2"
        )), 
      family = negbinomial(), 
      chains = nchains, 
      warmup = burnin, 
      iter = niter, 
      cores = nparallel, 
      backend = "cmdstanr")

effects <- conditional_effects(test, effects = "area_prop_sb_cat:regio", 
                               plot = FALSE)

effects_df <- effects$`area_prop_sb_cat:regio` %>%
  as_tibble()

effects_df %>%
  mutate(area_prop_sb_cat = factor(gsub("^area_", "", area_prop_sb_cat),
                                   levels = c("0", "<0.1", "0.1-0.2",
                                              ">0.2"),
                                   ordered = TRUE)) %>%
  ggplot(aes(x = area_prop_sb_cat, y = estimate__, colour = regio)) +
    geom_point(position = position_dodge(width = 0.4),
               size = 4 / 1^0.25) +
    geom_errorbar(aes(ymin = lower__, ymax = upper__),
                  position = position_dodge(width = 0.4),
                  width = 0.3) +
    facet_wrap(~regio) +
    theme(legend.position = "") +
    labs(x = "oppervlakte soorbeschermingsplannen",
         y = "aantal broedparen Gele kwikstaart")
```

Dit ziet er waardevoller uit.

## Selectie verklarende variabelen

<https://mc-stan.org/projpred/articles/projpred.html>\
<https://mc-stan.org/projpred/articles/latent.html>\
<https://github.com/stan-dev/projpred/issues/67>\
<https://paul-buerkner.github.io/brms/reference/R2D2.html>

Zie de McLatchie et al paper die ik onlangs doorstuurde.
Appendix B onder andere

### Referentiemodel

Eerst moeten we een referentiemodel construeren voor de selectie van verklarende variabelen via 'projection predive variable selection' (PPVS).
Het doel van PPVS is het vinden van een zo klein mogelijke subset van kandidaat-variabelen met een voorspellende kracht die zo dicht mogelijk ligt bij die van het referentiemodel.
Het referentiemodel bevat alle variabelen in kwestie en is het best presterende model (in termen van voorspellende prestaties) dat we tot onze beschikking hebben [@mclatchie2023].

We selecteren de data van de Oostelijke leemstreek van 2022. 
We centreren en schalen alle continue variabelen door te delen door de standaard deviatie.

```{r}
# Data
data_projpred <- gele_kwik_df2_2022 %>%
  filter(regio == "Oostelijke leemstreek") %>%
  mutate(area_prop_sb_cat = case_when(
    area_prop_sb == 0 ~ "area_0",
    area_prop_sb < 0.1 ~ "area_<0.1",
    area_prop_sb <= 0.2 ~ "area_0.1-0.2",
    TRUE ~ "area_>0.2"
  ))

data_projpred_scaled <- data_projpred %>%
  mutate(across(.cols = c(where(is.numeric), -aantal), 
                .fns = ~ as.numeric(scale(.x))))

# MCMC parameters
nchains <- 3           # number of chains
niter <- 8000         # number of iterations (incl. burn-in)
burnin <- niter / 4    # number of initial samples to discard (burn-in)
nparallel <- nchains   # number of cores used for parallel computing
thinning <- 2

# Formula
indices_refmodel1 <- which(names(data_projpred) %in% c(
  "id", 
  "aantal", 
  "plotnaam", 
  "regio",
  "jaar",
  "jaar.f",
  "area_prop_sb", 
  "area_prop_bo_overig",
  "area_prop_sb_cat",
  "x_plot",
  "y_plot",
  "is_sbp",
  "openheid_klasse_300"))
predictors_refmodel1 <- names(data_projpred)[-indices_refmodel1]

form_refmodel1 <- bf(paste("aantal", "~", paste(predictors_refmodel1, 
                                                collapse = " + ")))
form_refmodel1
```

Voor de regressiecoÃ«fficienten ($\beta$-parameters) gebruiken we de 'R2-D2 shrinkage prior' [@zhang2016; @yanchenko2021].
Voor het intercept gebruiken we de basis priors van **brms**.
Deze prior specificeert een verdeling voor $R^2$ en induceert dan een prior op de individuele $\beta$'s.
Het idee achter 'shrinkage priors' is om de geschatte parameters van een model naar een centrale waarde te trekken of ze naar nul te laten krimpen.
Deze regularisatie moedigt zo simpelere modellen aan en kunnen dus gebruikt worden in variabelenselectie.
Voor de hyperparameters gebruiken we de instellingen voor "laag-relevante variabelen" uit Appendix B van @mclatchie2023.

```{r}
# PRIORS
## R2D2
## default
R2D2_prior1 <- set_prior(R2D2(mean_R2 = 0.5, prec_R2 = 2, cons_D2 = 1, 
                              autoscale = TRUE))
## weakly-relevant predictors(McLatchie et al., 2023)
R2D2_prior2 <- set_prior(R2D2(mean_R2 = 0.3, prec_R2 = 5, cons_D2 = 10, 
                              autoscale = TRUE))
## random combinations
R2D2_prior3 <- set_prior(R2D2(mean_R2 = 0.3, prec_R2 = 5, cons_D2 = 1, 
                              autoscale = TRUE))
R2D2_prior4 <- set_prior(R2D2(mean_R2 = 0.5, prec_R2 = 5, cons_D2 = 5, 
                              autoscale = TRUE))

## Horseshoe
## default
hs_prior1 <- set_prior(horseshoe(
  df = 1,
  scale_global = 1,
  df_global = 1,
  scale_slab = 2,
  df_slab = 4,
  par_ratio = NULL,
  autoscale = TRUE
  ))

## https://mc-stan.org/projpred/articles/latent.html#example-poisson-distribution
D <- length(predictors_refmodel1)
N <- nrow(data_projpred)
# Prior guess for the number of relevant (i.e., non-zero) regression
# coefficients:
p0 <- 10
# Prior guess for the overall magnitude of the response values, see Table 1 of
# Piironen and Vehtari (2017, DOI: 10.1214/17-EJS1337SI):
mu_prior <- 1
# Hyperprior scale for tau, the global shrinkage parameter:
tau0 <- (p0 / (D - p0)) * (sqrt(mu_prior) / sqrt(N))

hs_prior2 <- set_prior(horseshoe(
  df = 1,
  scale_global = tau0,
  df_global = 1,
  scale_slab = 1,
  df_slab = 100,
  par_ratio = NULL,
  autoscale = TRUE
  ))

hs_prior3 <- set_prior(horseshoe(
  df = 1,
  scale_global = tau0,
  df_global = 1,
  scale_slab = 2,
  df_slab = 4,
  par_ratio = NULL,
  autoscale = TRUE
  ))

hs_prior4 <- set_prior(horseshoe(
  df = 1,
  scale_global = 10,
  df_global = 10,
  scale_slab = 2,
  df_slab = 100,
  par_ratio = NULL,
  autoscale = TRUE
  ))

priors_refmodel1 <- list(
  NULL,
  R2D2_prior1, R2D2_prior2, R2D2_prior3, R2D2_prior4,
  hs_prior1, hs_prior2, hs_prior3, hs_prior4)
```

We fitten de modellen met de Poisson verdeling m.b.v. **brms**.

```{r}
for (i in seq_along(priors_refmodel1)) {
  name <- paste0("ref_gelekwik_model", i)
  print(paste("Busy fitting", name, "..."))
  assign(name,
         brm(formula = form_refmodel1,
             data = data_projpred_scaled, 
               family = poisson(),
               prior = priors_refmodel1[[i]],
               chains = nchains, 
               warmup = burnin, 
               iter = niter,
               cores = nparallel,
               thin = thinning,
               sample_prior = TRUE,
               backend = "cmdstanr",
               file = paste0(model_path, name),
               file_refit = "on_change"))
}
```

#### MCMC convergentie

De Gelman-Rubin statistieken zijn dicht bij 1.

```{r}
show_rhat <- function(models) {
  # get rhats and make dataframe
  rhat_list <- lapply(seq_along(models), function(i) {
    model <- models[[i]]
    rhats <- rhat(model)
    as.data.frame(rhats) %>%
      rownames_to_column("variable") %>%
      rename_with(~paste0("rhat"), .cols = starts_with("rhat")) %>%
      mutate(model = paste0("model", i))
    })
  rhat_df <- do.call(rbind.data.frame, rhat_list)
  
  # visualise
  palette <- colorRampPalette(RColorBrewer::brewer.pal(9, name = 'Set1'))(length(unique(rhat_df$variable)))
  rhat_df %>%
    ggplot(aes(y = rhat, x = model, colour = variable)) +
      geom_hline(yintercept = c(1, 1.1), colour = "grey", linetype = "dashed") +
      geom_jitter(width = 0.2, height = 0) +
      scale_colour_manual(values = palette) +
      theme(legend.position = "") +
      labs(x = "")
}

```

```{r}
show_rhat(list(ref_gelekwik_model1,
               ref_gelekwik_model2,
               ref_gelekwik_model3,
               ref_gelekwik_model4,
               ref_gelekwik_model5,
               ref_gelekwik_model6,
               ref_gelekwik_model7,
               ref_gelekwik_model8))
```

Hoewel de verschillende chains overeenkomen in alle modellen, zien de posterior distributions er toch vreemd uit voor de modellen met de horseshoe priors. Het lijkt erop dat er sterke shrinkage naar 0 is maar dat dit voor een vreemde vorm in de posterior zorgt. Bovendien werden er verschillende warnings geuit tijdens het fitten van deze modellen.

Mogelijks is dit het gevolg van de keuzes van de hyperparameters. "Different levels of sparsity can be accommodated by changing the value of $\tau$: with large $\tau$ all the variables have very diffuse priors with very little shrinkage towards zero, but letting $\tau \rightarrow 0$ will shrink all the weights $\beta_j$ to zero." .

```{r}
plot(ref_gelekwik_model6)
plot(ref_gelekwik_model9)
```

#### Prior check

Hoe zien de R2D2 priors eruit?

```{r}
show_prior <- function(model, parameter, title = "") {
  if (parameter == "R2D2") {
    prior_check_samples <- prior_draws(model)
    posterior_sample_r2 <- bayes_R2(model, summary = FALSE)
    df_r2 <- data.frame(posterior = posterior_sample_r2[,1],
                        prior = prior_check_samples$R2D2_R2) %>%
      pivot_longer(c("posterior", "prior"), 
                   names_to = "distribution", values_to = "R2")
    
    ggplot(df_r2, aes(x = R2, colour = distribution)) +
      geom_density() +
      ggtitle(title) +
      theme(plot.title = element_text(size = 10))
    }
  }
```

```{r}
grid.arrange(show_prior(ref_gelekwik_model2, "R2D2", 
                        "mean_R2 = 0.5, prec_R2 = 2, cons_D2 = 1"),
             show_prior(ref_gelekwik_model3, "R2D2", 
                        "mean_R2 = 0.3, prec_R2 = 5, cons_D2 = 10"),
             show_prior(ref_gelekwik_model4, "R2D2", 
                        "mean_R2 = 0.3, prec_R2 = 5, cons_D2 = 1"),
             show_prior(ref_gelekwik_model5, "R2D2", 
                        "mean_R2 = 0.5, prec_R2 = 5, cons_D2 = 5"))
```

Hoe zien de horseshoe priors eruit?

```{r}
prior_check_samples6 <- prior_draws(ref_gelekwik_model6)
p1 <- prior_check_samples6 %>%
  ggplot(aes(x = hs_global)) +
    geom_density() +
    ggtitle("ref_gelekwik_model6")
p2 <- prior_check_samples6 %>%
  ggplot(aes(x = hs_slab)) +
    geom_density() +
    ggtitle("ref_gelekwik_model6")

prior_check_samples7 <- prior_draws(ref_gelekwik_model7)
p3 <- prior_check_samples7 %>%
  ggplot(aes(x = hs_global)) +
    geom_density() +
    ggtitle("ref_gelekwik_model7")
p4 <- prior_check_samples7 %>%
  ggplot(aes(x = hs_slab)) +
    geom_density() +
    ggtitle("ref_gelekwik_model7")

prior_check_samples8 <- prior_draws(ref_gelekwik_model8)
p5 <- prior_check_samples8 %>%
  ggplot(aes(x = hs_global)) +
    geom_density() +
    ggtitle("ref_gelekwik_model8")
p6 <- prior_check_samples8 %>%
  ggplot(aes(x = hs_slab)) +
    geom_density() +
    ggtitle("ref_gelekwik_model8")

prior_check_samples9 <- prior_draws(ref_gelekwik_model9)
p7 <- prior_check_samples9 %>%
  ggplot(aes(x = hs_global)) +
    geom_density() +
    ggtitle("ref_gelekwik_model9")
p8 <- prior_check_samples9 %>%
  ggplot(aes(x = hs_slab)) +
    geom_density() +
    ggtitle("ref_gelekwik_model9")

grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol = 2)
```

#### Posterior predictive check

Model fit ok.

```{r}
pp_check(ref_gelekwik_model1, type = "bars", ndraws = 200)
```

```{r}
pp_check(ref_gelekwik_model2, type = "bars", ndraws = 200)
```

```{r}
pp_check(ref_gelekwik_model6, type = "bars", ndraws = 200)
```

### Selectie variabelen

PPVS kunnen we doen met de **projpred** package [@projpred].
Een eerste en relatief snelle run met de `cv_varsel()` functie kan een ruw idee geven van de prestaties van de submodellen en kan het gebruikt worden voor het vinden van een geschikte waarde voor argument `nterms_max` in volgende runs (argument nterms_max legt een limiet op aan de submodelgrootte tot waar verder gezocht wordt en kan zo de runtime aanzienlijk verkorten). 
Default neemt de functie 19 als maximum, maar wij schatten dat meer dan 10 predictors overbodig zal zijn.
Omdat we de variabele `sbp` in elk model willen, maken we een vector met alle mogelijke combinaties van predictors met deze variabele en maximum aan 10 predictors.
`nterms_max` zal dan automatisch 10 zijn.
Het duurt vrij lang om deze combinaties te berekenen (zie [deze issue](https://github.com/stan-dev/projpred/issues/346) voor toekomstige verbetering in **projpred**).

```{r}
combm_predictors <- function(m, predictors) {
  lapply(combn(predictors, m = m, simplify = FALSE), 
         function(vars) paste(vars, collapse = " + ")
         )
  }

get_search_terms <- function(n_predictors_max, predictors, keep_var) {
  n_predictors <- n_predictors_max - length(keep_var)
  search_terms <- unlist(lapply(seq_len(n_predictors), 
                                function(m) combm_predictors(m, predictors)))
  out <- c(keep_var, paste(keep_var, search_terms, sep = " + "))
  return(out)
}
```

```{r}
search_terms_refmodel1 <- get_search_terms(
  n_predictors_max = 2, 
  predictors = predictors_refmodel1[-match("sbp", predictors_refmodel1)],
  keep_var = "sbp")
```

Ook kan het interessant zijn dit te doen voor zowel het model met als zonder shrinkage prior.

Zonder shrinkage prior:

```{r}
# Fast varsel for first exploration
start_cvvs_fast1 <- Sys.time()
cvvs_fast1 <- cv_varsel(ref_gelekwik_model1,
                            method = "forward",
                            nclusters_pred = 20, # speed
                            cv_method = "LOO",
                            search_terms = search_terms_refmodel1,
                            # only for the sake of speed
                            validate_search = FALSE)
end_cvvs_fast1 <- Sys.time()
end_cvvs_fast1 - start_cvvs_fast1
```

```{r}
cvvs_fast1
plot(cvvs_fast1, stats = "mlpd", ranking_nterms_max = NA)
```

De aangeraden modelgrootte is:

```{r}
suggest_size(cvvs_fast1)
```

Met R2D2 prior (1):

```{r}
# Fast varsel for first exploration
start_cvvs_fast2 <- Sys.time()
cvvs_fast2 <- cv_varsel(ref_gelekwik_model2,
                       method = "forward",
                       nclusters_pred = 20, # speed
                       cv_method = "LOO",
                       search_terms = search_terms_refmodel1,
                       # only for the sake of speed
                       validate_search = FALSE)
end_cvvs_fast2 <- Sys.time()
end_cvvs_fast2 - start_cvvs_fast2
```

```{r}
cvvs_fast2
plot(cvvs_fast2, stats = "mlpd", ranking_nterms_max = NA)
```

De aangeraden modelgrootte is:

```{r}
suggest_size(cvvs_fast2)
```

Met R2D2 prior (2):

```{r}
# Fast varsel for first exploration
start_cvvs_fast3 <- Sys.time()
cvvs_fast3 <- cv_varsel(ref_gelekwik_model3,
                       method = "forward",
                       nclusters_pred = 20, # speed
                       cv_method = "LOO",
                       search_terms = search_terms_refmodel1,
                       # only for the sake of speed
                       validate_search = FALSE)
end_cvvs_fast3 <- Sys.time()
end_cvvs_fast3 - start_cvvs_fast3
```

```{r}
cvvs_fast3
plot(cvvs_fast3, stats = "mlpd", ranking_nterms_max = NA)
```

De aangeraden modelgrootte is:

```{r}
suggest_size(cvvs_fast3)
```

Met horseshoe prior (4):

```{r}
# Fast varsel for first exploration
start_cvvs_fast4 <- Sys.time()
cvvs_fast4 <- cv_varsel(ref_gelekwik_model9,
                       method = "forward",
                       nclusters_pred = 20, # speed
                       cv_method = "LOO",
                       search_terms = search_terms_refmodel1,
                       # only for the sake of speed
                       validate_search = FALSE)
end_cvvs_fast4 <- Sys.time()
end_cvvs_fast4 - start_cvvs_fast4
```

```{r}
cvvs_fast4
plot(cvvs_fast4, stats = "mlpd", ranking_nterms_max = NA)
```

De aangeraden modelgrootte is:

```{r}
suggest_size(cvvs_fast4)
```

Hoe sterker de shrinkage, hoe sneller PPVS. De horseshoe had de sterkste shrinkage, daarna de R2D2 en daarna zonder shrinkage. Zonder shrinkage prior gaat het trager en de resultaten verschillen ook van deze met de shrinkage priors.
Omwille van de model fit problemen, lijkt het best om verder te gaan met het model met de default R2D2 shrinkage prior.

We zien dat de "mean log predictive density" (MLPD) van de shrinkage submodellen vooral hard toeneemt bij de eerste vier predictors. Daarna zijn er slechts kleine verschillen.
Nu doen we een grondige forward search die meer tijd nodig heeft met `validate_search = TRUE` (beschermt tegen overfitting).
Om op veilig te spelen zetten we  `nterms_max = 10`.
We maken dezelfde plot als voordien maar nu als verschil met ons referentiemodel (`deltas = TRUE`).

```{r}
cvvs_file <- paste0(projpred_path, "cvvs_refmodel1.rds")
if (!file.exists(cvvs_file)) {
  cvvs_refmodel1 <- cv_varsel(
    object          = ref_gelekwik_model2,
    method          = "forward",
    cv_method       = "LOO",
    search_terms    = search_terms_refmodel1,
    nterms_max = 10,
    validate_search = TRUE)
  saveRDS(cvvs_refmodel1, cvvs_file)
} else {
  cvvs_refmodel1 <- readRDS(cvvs_file)
}

plot(cvvs_file, stats = "mlpd", deltas = TRUE, ranking_abbreviate = TRUE, 
     ranking_abbreviate_args = list(minlength = 4))
```

Op basis van deze plot bepalen we submodelgrootte. 
Meestal is het de bedoeling om de kleinste submodelgrootte te vinden waarbij de voorspellende prestaties van de submodellen afvlakken en dicht genoeg in de buurt komen van de voorspellende prestaties van het referentiemodel (de gestippelde rode horizontale lijn).
Dit blijft min of meer een subjectieve beslissing.
Er moet er een geschikte afweging worden gemaakt tussen voorspellende prestaties (nauwkeurigheid) en modelgrootte.
We zien na de vierde predictor geen sterke stijgingen meer. 
Wel is er nog een kleine stijging tot en met 7 Ã  8.

```{r}
smmry <- summary(cvvs_file, stats = "mlpd", type = c("mean", "lower", "upper"),
                 deltas = TRUE)
print(smmry, digits = 1)
```

De eerste vier zijn dezelfde als de eerste vier in de snelle analyse. Dit geld ook voor de eerste acht (wel in andere volgorde).
We zien bovendien dat voor de eerste acht predictors dat er weinig variabiliteit is in de rangschikking van de variabelen

```{r}
rk <- ranking(cvvs_file)
pr_rk <- cv_proportions(rk)
plot(pr_rk)
plot(cv_proportions(rk, cumulate = TRUE))
```

4 of 8? 8 is goed zie ook snelle methode zelfde resultaat ...

```{r}
suggest_size(cvvs_file, stat = "mlpd")
size_decided <- suggest_size(cvvs_file, stat = "mlpd")
predictors_final <- head(rk[["fulldata"]], size_decided)
predictors_final
```

```{r}
plot(cv_proportions(rk, cumulate = TRUE))
```

```{r}
size_decided <- 8
predictors_final <- head(rk[["fulldata"]], size_decided)
predictors_final
```

```{r}
plot(cv_proportions(rk, cumulate = TRUE))
```



# Referenties
