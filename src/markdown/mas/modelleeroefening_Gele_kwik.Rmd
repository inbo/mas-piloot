---
title: "Modelleren en distance sampling Gele kwikstaart"
author: "Ward Langeraert"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
renv::restore()
library(rstan)
library(mapview)
library(INLA)
library(inlatools)
library(Distance)
library(territoria)
library(DBI)
library(unmarked)
library(Hmisc)
library(knitr)
library(here)
opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE)
opts_knit$set(root.dir = here::here())
library(tidyverse)
library(gridExtra)
library(sf)
library(lubridate)
library(targets)
library(terra)
library(brms)
targets_store <- here("src", "targets", "mas_steekproef_pilootfase", "_targets")
source(here("src", "R", "berekening_hulpvariabelen.R"))
source(here("src", "R", "wfs_wcs.R"))
```


# Inlezen data

```{r ronde-intervallen}
r1_start <- "04-01"
r1_stop <- "04-20"
r2_start <- "04-21"
r2_stop <- "05-10"
r3_start <- "05-11"
r3_stop <- "06-10"
r4_start <- "06-21"
r4_stop <- "07-15"
```

```{r inlezen-mas-data}
mas <- read_sf(
  here("data/mas/20220906_qgis_export_sovon_wfs.gpkg")) %>%
  mutate(
    datum = ymd(paste(jaar, maand, dag, sep = "-")),
    periode_in_jaar = case_when(
      datum %within% interval(
        ymd(paste(jaar, r1_start, sep = "-")),
        ymd(paste(jaar, r1_stop, sep = "-"))) ~ "R1",
      datum %within% interval(
        ymd(paste(jaar, r2_start, sep = "-")),
        ymd(paste(jaar, r2_stop, sep = "-"))) ~ "R2",
      datum %within% interval(
        ymd(paste(jaar, r3_start, sep = "-")),
        ymd(paste(jaar, r3_stop, sep = "-"))) ~ "R3",
      datum %within% interval(
        ymd(paste(jaar, r4_start, sep = "-")),
        ymd(paste(jaar, r4_stop, sep = "-"))) ~ "R4"
    ))
```

CRS moet aangepast worden naar Lambert 72.

```{r, project-crs}
# Belgian Lambert 72
proj_crs <- 31370

# Herbereken x en y-coÃ¶rdinaten in Lambert 72
coordinates <- mas %>% 
  st_transform(crs = proj_crs) %>%
  st_coordinates() %>%
  as_tibble() %>%
  rename(x_coord = X, y_coord = Y)

mas <- mas %>% 
  st_transform(crs = proj_crs) %>%
  select(-c(x_coord, y_coord)) %>%
  cbind(coordinates)
```

```{r design2022}
design2022 <- read_csv(here(
    "data",
    "processed",
    "steekproef_piloot_avimap.csv")) %>%
  select(plotnaam = definitief_punt,
         regio,
         stratum) %>%
  mutate(openheid = ifelse(grepl("HOL", stratum), "HOL", "OL"),
         sbp = ifelse(grepl("binnen", stratum), "binnen", "buiten"),
         stratum = gsub("L\\s{1}", "L\\\n", stratum))
```

```{r design-2018-2022}
telpunten_avimap_2021 <- read_sf(
  here("data", "mas",
       "avimap_514_0_MAS_Werkgroep_Grauwe_Kiekendief_Belgi__telpunten_xy.shp")
) %>%
  rename(teller_2021 = teller) %>%
  mutate(
    regio = ifelse(is.na(regio), "Vlaanderen - Bilzen", regio),
    type_teller_2021 = case_when(
      teller_2021 %in% c("WVNT00", "JJNN16", "NOVN00") |
        regio == "Vlaanderen - Leefdaal" ~ "professioneel",
      is.na(teller_2021) &
        regio != "Vlaanderen - Leefdaal" ~ "niet geteld in 2021",
      TRUE ~ "vrijwilliger")) %>%
  select(-st_x, -st_y)

perimeters <- read_sf(
  here("data", "processed", "piloot_perimeters.gpkg"))

vlaanderen <- get_feature_wfs(
  wfs = "https://eservices.minfin.fgov.be/arcgis/services/R2C/Regions/MapServer/WFSServer",
  layername = "regions",
  crs = "EPSG:31370",
  filter = "<Filter><PropertyIsEqualTo><PropertyName>regions:NameDUT</PropertyName><Literal>'Vlaams Gewest'</Literal></PropertyIsEqualTo></Filter>") %>%
  select(NameDUT)


sbp_akkervogels <- tar_read(sbp_akkervogels,
                            store = targets_store)

design_2018_2021 <- add_openheid_landschap_to_frame(
  path = here("data", "dem",
    "openness300m_chm_res25_c300_mean_vlaanderen.tif"),
  punten_sf = telpunten_avimap_2021,
  gebied = vlaanderen,
  cutlevels = c(1.25, 1.35, 1.51),
  class_labels = c("GL", "HGL", "HOL", "OL")) %>%
  select(plotnaam = naam, regio, openheid = openheid_klasse) %>%
  mutate(sbp = st_intersects(.,
                             st_union(sbp_akkervogels),
                             sparse = FALSE) %>%
           as.logical(),
         sbp = ifelse(sbp, "binnen", "buiten")
  ) %>%
  st_drop_geometry() %>%
  mutate(stratum = paste0(openheid, "\n", sbp, " plan"),
         regio = gsub("Vlaanderen - ", "", regio),
         regio = ifelse(regio == "Leemstreek", "Oostelijke leemstreek", regio))
 
plotlijst_2018_2022 <- mas %>%
  st_drop_geometry() %>%
  distinct(plotnaam) %>%
  arrange(plotnaam)

design_2018_2022 <- bind_rows(
  design_2018_2021,
  design2022) %>%
  distinct() %>%
  arrange(plotnaam)
# er zitten duplos in (zie volgende chunk)
```

```{r probleemgevallen, eval=FALSE}
# probleemgevallen met verschillende classificatie
is_duplo <- duplicated(design_2018_2022$plotnaam)
duplo_plotnaam <- design_2018_2022 %>%
  select(plotnaam) %>%
  filter(is_duplo)
design_2018_2022 %>%
  inner_join(duplo_plotnaam) %>%
  View()

# volgens bestand buiten plan, maar lijkt niet te kloppen
# iets mis in targets analyse pipeline?
avimap <- telpunten_avimap_2021 %>%
  filter(naam == "VL0003")

read_csv(here(
    "data",
    "processed",
    "steekproef_piloot_avimap.csv")) %>%
  filter(definitief_punt == "VL0003") %>%
  st_as_sf(coords = c("X", "Y"), crs = proj_crs) %>%
  mapview::mapview()  +
  mapview::mapview(sbp_akkervogels, col.regions = "yellow") +
  mapview::mapview(avimap)

read_csv(here(
    "data",
    "processed",
    "steekproef_piloot_avimap.csv")) %>%
  inner_join(duplo_plotnaam, by = c("definitief_punt" = "plotnaam")) %>%
  st_as_sf(coords = c("X", "Y"), crs = proj_crs) %>%
  mapview::mapview()  +
  mapview::mapview(sbp_akkervogels, col.regions = "yellow")
```

```{r omzeilen-probleemgevallen}
# probleemgevallen voorlopig omzeilen
design_2018_2022 <- bind_rows(
  design_2018_2021,
  design2022 %>%
    filter(!grepl("^VL", plotnaam))) %>%
  distinct() %>%
  arrange(plotnaam)
```

```{r overzicht-data, eval=FALSE}
head(mas)
summary(mas)
glimpse(mas)
```

Dubbeltellingen zijn eruit (soort gezien op meerdere teldagen binnen eenzelfde telperiode): in dat geval de laatste teldag genomen.

```{r check-dubbeltelling}
dubbels <- mas %>%
  st_drop_geometry() %>%
  group_by(plotid, jaar, periode_in_jaar, soortnr) %>%
  summarize(aantal_teldagen = n_distinct(doy),
            .groups = "drop") %>%
  filter(aantal_teldagen > 1)
# kan zowel zelfde waarnemer als andere waarnemer zijn

mas_clean <- mas %>%
  semi_join(dubbels, by = c("plotid", "jaar", "periode_in_jaar")) %>%
  group_by(plotid, jaar, periode_in_jaar) %>%
  filter(doy == max(doy)) %>%
  ungroup() %>%
  bind_rows(mas %>%
              anti_join(dubbels, by = c("plotid", "jaar", "periode_in_jaar")))
```


# Gele kwikstaart 2022{#gele-kwik}

We starten met een beperkte dataset om het aantal broedparen van de Gele kwikstaart te modelleren. We beginnen met data exploratie en bouwen dan verschillende modellen op van simpel naar meer complexe modellen. 

We selecteren de data voor Gele kwikstaart van 2022 met broedcode > 0. Opmerking: wat met *Gele kwikstaart (spec)*?

```{r selectie-gelekwik-2022}
# Selecteer tellingen van Gele kwikstaart in 2022 in de twee regios
# met broedcode > 0 en binnen telrondes
gele_kwik_2022_presences <- mas_clean %>% 
  st_drop_geometry() %>%
  filter(naam == "Gele Kwikstaart", jaar == 2022, 
         !is.na(periode_in_jaar), wrntype > 0L) %>%  
  inner_join(design2022, by = "plotnaam") # Moeren en Leemstreek

# Totale lijst van bezochte plots in 2022
bezoekenlijst_2022 <- design2022 %>% 
  expand_grid(distinct(mas_clean, periode_in_jaar)) %>% # voeg telperiodes toe
  filter(!is.na(periode_in_jaar))

# Voeg afwezigheden toe door te mergen met alle bezoeken
gele_kwik_2022 <- gele_kwik_2022_presences %>%
  group_by(plotnaam, periode_in_jaar) %>%
  summarise(aantal = sum(aantal)) %>% # som aantallen gespot per dag 
  full_join(bezoekenlijst_2022, by = c("plotnaam", "periode_in_jaar")) %>%
  replace(is.na(.), 0) %>%
  arrange(plotnaam, periode_in_jaar)
```


## Data exploratie{#exploratie}

Enkele samenvattende statistieken:

```{r stats-aantallen-nodist}
gele_kwik_2022 %>%
  group_by(regio, periode_in_jaar) %>%
  summarise(min = min(aantal), 
            mediaan = median(aantal),
            gemiddelde = mean(aantal),
            max = max(aantal),
            varantie = var(aantal)) %>%
  kable()
```

We zien dat de gemiddeldes en de variantie ongeveer gelijk zijn zodat we mogelijks geen overdispersie hebben.  
  
Aantal tellingen per categorie:

```{r tellingen-aantallen-nodist}
gele_kwik_2022 %>%
  group_by(regio, periode_in_jaar, aantal) %>%
  summarise(n = n(), .groups = "drop") %>%
  arrange(aantal) %>%
  pivot_wider(names_from = aantal, values_from = n) %>%
  replace(is.na(.), 0) %>%
  kable()
```

Verdeling van de tellingen:

```{r histogram-aantallen-nodist}
gele_kwik_2022 %>%
  group_by(regio, periode_in_jaar, aantal) %>%
  summarise(n = n(), .groups = "drop_last") %>%
  ggplot(aes(x = aantal, y = n, fill = regio)) +
    geom_bar(stat = "identity", col = "black") +
    theme(panel.grid.minor.x = element_blank(),
          panel.grid.major.x = element_blank()) + 
    facet_wrap(~periode_in_jaar, scales = "free") +
    labs(y = "", x = "Aantal broedparen Gele kwikstaart per plot")
```

Totaal aantal getelde broedparen Gele kwikstaart per telcirkel met aanduiding van gemiddelde en 95% bootstrap betrouwbaarheidsinterval.

```{r boxplots-aantallen-nodist}
gele_kwik_2022 %>%
  ggplot(aes(x = periode_in_jaar, y = aantal, colour = periode_in_jaar)) +
  stat_sum(position = position_dodge(width = 0.5), alpha = 0.5) +
  stat_summary(fun.data = mean_cl_boot,
               position = position_dodge(width = 0.5),
               fatten = 4, shape = "square") +
  facet_wrap(~regio) +
  labs(y = "Aantal broedparen Gele kwikstaart per plot", x = "Telperiode")
```


## Generalized linear mixed models{#GLMM}

### brms package{#brms}

**Op verkenning**

Voorlopig houden we geen rekening met detectiekans. We sommen de aantallen op per plot per telperiode (elke plot is 1x per telperiode bezocht). Met deze data fitten we een model waarbij de aantallen broedparen Gele kwikstaart per telcirkel afhangen van regio en een effect van tijdstip van de telling in 2022. Als random effect wordt de plot in het model gestoken om rekening te houden met gepaardheid van de waarnemingen doorheen het jaar. 

We fitten vier modellen met verschillende verdelingsassumpties:

1. Poisson
2. Negative binomial
3. Zero-inflated Poisson
4. Zero-inflated Negative binomial

<span style="color: red;">opmerking:</span> Met de optie `sample_prior = "only"` kunnen bijkomend trekkingen worden getrokken van de priors, waarbij de likelihood wordt genegeerd. Daarmee kan er gesampled worden van de prior predictive distribution. Hiermee kunnen de gebruikte priors gecontroleerd worden. Echter deze optie is nu niet mogelijk aangezien sommige parameters improper priors hebben: `Error occurred for parameter 'b'.`.

```{r fit-GLMMs, results=FALSE, fig.show='hide'}
# Save brms models to this path
model_path <- "./src/markdown/mas/brms_models/"
models <- c("Poisson", "Negative binomial", "Zero-inflated Poisson", 
            "Zero-inflated Negative binomial")

# MCMC parameters
nchains <- 3           # number of chains
niter <- 4000          # number of iterations (incl. burn-in)
burnin <- niter / 2    # number of initial samples to discard (burn-in)
nparallel <- nchains   # number of cores used for parallel computing

# 1. Poisson
brmpois1 <- brm(bf(aantal ~ regio + periode_in_jaar + (1 | plotnaam)), 
                data = gele_kwik_2022, family = poisson(), 
                chains = nchains, warmup = burnin, iter = niter, 
                cores = nparallel,
                file = paste0(model_path, "brmpois1"),
                file_refit = "on_change")
summary(brmpois1)
plot(brmpois1)

# 2. Negative binomial
brmnegbin1 <- brm(bf(aantal ~ regio + periode_in_jaar + (1 | plotnaam)), 
                  data = gele_kwik_2022, family = negbinomial(), 
                  chains = nchains, warmup = burnin, iter = niter, 
                  cores = nparallel,
                  file = paste0(model_path, "brmnegbin1"),
                  file_refit = "on_change")
summary(brmnegbin1)
plot(brmnegbin1)

# 3. Zero-inflated Poisson
brmZIP1 <- brm(bf(aantal ~ regio + periode_in_jaar + (1 | plotnaam)), 
               data = gele_kwik_2022, family = zero_inflated_poisson(), 
               chains = nchains, warmup = burnin, iter = niter, 
               cores = nparallel,
               file = paste0(model_path, "brmZIP1"),
               file_refit = "on_change")
summary(brmZIP1)
plot(brmZIP1)

# 4. Zero-inflated Negative binomial
brmZINB1 <- brm(bf(aantal ~ regio + periode_in_jaar + (1 | plotnaam)), 
                data = gele_kwik_2022, family = zero_inflated_negbinomial(), 
                chains = nchains, warmup = burnin, iter = niter, 
                cores = nparallel,
                file = paste0(model_path, "brmZINB1"),
                file_refit = "on_change")
summary(brmZINB1)
plot(brmZINB1)
```

Convergentie voor alle modellen ok (scale reduction factors, trace plots, posterior density).

**Model selectie en fit**

We vergelijken de modellen gebruikmakend van 5-fold cross-validation (CV) (leave one out CV en WAIC berekenen niet mogelijk, <span style="color: red;">waarom?</span>). Eerst worden de gegevens opgedeeld in $K$ delen (subsets) van gelijke (of zo goed mogelijk gelijke) grootte. Vervolgens wordt het model $K$ keer gefit, waarbij telkens een van de $K$ subsets wordt weggelaten. We stratificeren volgens regio. Hierbij wordt er voor gezorgt dat relatieve frequenties per regio bij benadering behouden blijven.

```{r k-foldCV-GLMMs}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_brmpois1.rds"))) {
  fit_brmpois1 <- add_criterion(brmpois1, c("kfold"), K = 5, cores = 5,
                                folds = "stratified", group = "regio", 
                                file = paste0(model_path, "fit_brmpois1"))
  fit_brmnegbin1 <- add_criterion(brmnegbin1, c("kfold"), K = 5, cores = 5, 
                                folds = "stratified", group = "regio", 
                                file = paste0(model_path, "fit_brmnegbin1"))
  fit_brmZIP1 <- add_criterion(brmZIP1, c("kfold"), K = 5, cores = 5,
                                folds = "stratified", group = "regio", 
                                file = paste0(model_path, "fit_brmZIP1"))
  fit_brmZINB1 <- add_criterion(brmZINB1, c("kfold"), K = 5, cores = 5,
                                folds = "stratified", group = "regio",
                                file = paste0(model_path, "fit_brmZINB1"))
} else {
  fit_brmpois1 <- readRDS(paste0(model_path, "fit_brmpois1.rds"))
  fit_brmnegbin1 <- readRDS(paste0(model_path, "fit_brmnegbin1.rds"))
  fit_brmZIP1 <- readRDS(paste0(model_path, "fit_brmZIP1.rds"))
  fit_brmZINB1 <- readRDS(paste0(model_path, "fit_brmZINB1.rds"))
}

# Comparison among models
comparisons <- loo_compare(fit_brmpois1, fit_brmnegbin1, fit_brmZIP1, 
                           fit_brmZINB1, criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                mutate(model = c("Poisson", "Zero-inflated Negative binomial",
                                 "Zero-inflated Poisson", "Negative binomial"))
```

```{r table-CV-GLMMs}
rbind(fit_brmpois1$criteria$kfold$estimates[, "Estimate"],
  fit_brmnegbin1$criteria$kfold$estimates[, "Estimate"],
  fit_brmZIP1$criteria$kfold$estimates[, "Estimate"], 
  fit_brmZINB1$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = models) %>%
  full_join(comparisons, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, everything()) %>%
  arrange(desc(elpd_diff)) %>%
  kable(digits = 3)
```

Het Poisson model toont het beste evenwicht tussen model parsimonie en model fit. Dat zien we ook bij de posterior predictive check. We vergelijken de waargenomen tellingen met gesimuleerde tellingen van de posterior predictive distribution. Bovendien voorspelt dit model geen onmogelijk grote waarden (ZINB voorspelt bijvoorbeeld grotere maxima terwijl we in de data slechts maximaal 6 individuen hadden).

```{r ppcheck-final-GLMM}
pp_check(fit_brmpois1, type = "bars_grouped", ndraws = 100, group = "regio",
         facet_args = list(ncol = 1, scales = "free_y"))

pp_check(fit_brmpois1, type = "bars_grouped", ndraws = 100, 
         group = "periode_in_jaar",
         facet_args = list(ncol = 1, scales = "free_y"))
```

**Resultaten en visualisatie**

Overzicht van de gefitte modelparameters, hun onzekerheid en enkele maten die aangeven of het model geconvergeerd is.

```{r parameters-final-GLMM}
summary(fit_brmpois1)
```

Visualisatie van de modelpredicties voor de verschillende regios en telperiodes.

```{r prediction-plots-final-GLMM}
pred <- conditional_effects(fit_brmpois1, effects = c("regio:periode_in_jaar"))

cirkelopp <- pi * 300^2
plot(pred, plot = FALSE)[[1]] + 
     scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
       name = "Aantal broedparen Gele kwikstaart per 100 ha")) +
     labs(y = "Aantal broedparen Gele kwikstaart per plot", x = "")
```

Testen van een hypothese. Voorbeeld: Is het gemiddeld aantal broedparen Gele kwikstaart significant lager in de Oostelijke leemstreek dan in De Moeren?

Hypothese:

\begin{aligned}
  &\frac{\exp(\beta_0) + \exp(\beta_0 + \beta_2) + \exp(\beta_0 + \beta_3) + \exp(\beta_0 + \beta_4)}{4} > \frac{\exp(\beta_0 + \beta_1) + \exp(\beta_0 + \beta_1 + \beta_2) + \exp(\beta_0 + \beta_1 + \beta_3) + \exp(\beta_0 + \beta_1 + \beta_4)}{4}\\
  &\Rightarrow \exp(\beta_0)(\exp(\beta_2) + \exp(\beta_3) + \exp(\beta_4)) > \exp(\beta_0)\exp(\beta_1)(\exp(\beta_2) + \exp(\beta_3) + \exp(\beta_4))\\
  &\Rightarrow \exp(\beta_1) < 1\\
  &\Rightarrow \beta_1 < 0
\end{aligned}

```{r hypothesis-regio}
hyp1 <- hypothesis(
  x = fit_brmpois1,
  "regioOostelijkeleemstreek < 0",
  class = "b", alpha = 0.05)
hyp1
plot(hyp1)
```

De evidence ratio is groot wat er op duidt dat er gemiddeld gezien een significant hoger aantal broedparen Gele kwikstaart in De Moeren aanwezig zijn. De evidence ratio is de verhouding tussen posterior probability a < b t.o.v. posterior probability a > b. De schatting is -0.47. Dit is een verschil in de log-schaal, dus als we dit exponentiÃ«ren bekomen we 0.63 keer minder broedparen Gele kwikstaart in de Oostelijke leemstreek dan in De Moeren.

Het toevoegen van een interactie `regio:periode_in_jaar` blijkt geen meerwaarde voor het model:

```{r GLMM-interaction, results=FALSE, fig.show='hide'}
brmpois2 <- brm(bf(aantal ~ regio + periode_in_jaar + regio:periode_in_jaar +
                     (1 | plotnaam)), 
                  data = gele_kwik_2022, family = poisson(), 
                  chains = nchains, warmup = burnin, iter = niter, 
                  cores = nparallel,
                  file = paste0(model_path, "brmpois2"),
                  file_refit = "on_change")

# Convergence ok
summary(brmpois2)
plot(brmpois2)
```

- Interactieparameters niet significant verschillend van nul.

```{r GLMM-interaction-hypotheses}
# Hypotheses
q1 <- "regioOostelijkeleemstreek:periode_in_jaarR2 = 0"
q2 <- "regioOostelijkeleemstreek:periode_in_jaarR3 = 0"
q3 <- "regioOostelijkeleemstreek:periode_in_jaarR4 = 0"

hypothesis(x = brmpois2, c(q1, q2, q3), class = "b", alpha = 0.05)
```

- K-fold cross-validation beter zonder interactie (toch grote standard error, maar dan opteren we voor het eenvoudigere model, i.e. zonder interactie)

```{r GLMM-interaction-CV}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_brmpois2.rds"))) {
  fit_brmpois2 <- add_criterion(brmnegbin1, c("kfold"), K = 5, cores = 5,
                        folds = "stratified", group = "regio", 
                        file = paste0(model_path, "fit_brmpois2"))
} else {
  fit_brmpois2 <- readRDS(paste0(model_path, "fit_brmpois2.rds"))
}

# Comparison among models
comparisons <- loo_compare(fit_brmpois1, fit_brmpois2, 
                           criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                mutate(model = c("Poisson: no interaction", 
                                 "Poisson: interaction"))

# Make nice table
rbind(fit_brmpois1$criteria$kfold$estimates[, "Estimate"],
  fit_brmpois2$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = c("Poisson: no interaction", "Poisson: interaction")) %>%
  full_join(comparisons, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, everything()) %>%
  kable(digits = 3)
```

- Visueel slechts klein verschil in predicties: R2 vs R3 De Moeren. Dat verschil zagen we ook al in de verkennende plot met bootstrap

```{r GLMM-visual-comparison-interaction}
pred_interaction <- conditional_effects(brmpois2, 
                                        effects = c("regio:periode_in_jaar"))

p_pois1 <- plot(pred, plot = FALSE)[[1]] + 
                scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
                  name = ""), limits = c(0, 0.4)) +
                labs(y = "Aantal broedparen Gele kwikstaart per plot", x = "", 
                     title = "Poisson: no interaction") +
                theme(legend.position = "bottom")

p_pois2 <- plot(pred_interaction, plot = FALSE)[[1]] + 
                scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
                  name = "Aantal broedparen Gele kwikstaart per 100 ha"), 
                  limits = c(0, 0.4)) +
                labs(y = "", x = "", title = "Poisson: interaction") +
                theme(legend.position = "bottom")

grid.arrange(p_pois1, p_pois2, ncol = 2)
```

### INLA package{#INLA}

**Op verkenning**

Dit is als oefening/voorbereiding op meer complexe analyses verderop. Kunnen we de resultaten van **brms** repliceren met deze package?

Handige links:
https://www.flutterbys.com.au/stats/tut/tut12.10.html  
https://inbo.github.io/tutorials/tags/inla/  
https://rpubs.com/Jqedwards/841168  

We fitten opnieuw vier modellen met verschillende verdelingsassumpties.

```{r}
# 1. Poisson
inlapois1 <- inla(aantal ~ regio + periode_in_jaar + f(plotnaam, model = "iid"), 
                  data = gele_kwik_2022, family = "poisson",
                  control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

# 2. Negative binomial
inlanb1 <- inla(aantal ~ regio + periode_in_jaar + f(plotnaam, model = "iid"), 
                data = gele_kwik_2022, family = "nbinomial",
                control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

# 3. Zero-inflated Poisson
inlaZIP1 <- inla(aantal ~ regio + periode_in_jaar + f(plotnaam, model = "iid"), 
                 data = gele_kwik_2022, family = "zeroinflatedpoisson1",
                 control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))

# 4. Zero-inflated Negative binomial
inlaZINB1 <- inla(aantal ~ regio + periode_in_jaar + f(plotnaam, model = "iid"), 
                  data = gele_kwik_2022, family = "zeroinflatednbinomial1",
                  control.compute = list(dic = TRUE, waic = TRUE, cpo = TRUE))
```

**Model selectie en fit**

```{r}
tibble(model = c("Poisson", "Negative binomial", "Zero-inflated Poisson", 
                 "Zero-inflated Negative binomial"),
       WAIC = c(inlapois1$waic$waic, inlanb1$waic$waic, inlaZIP1$waic$waic, 
                inlaZINB1$waic$waic),
       DIC = c(inlapois1$dic$dic, inlanb1$dic$dic, inlaZIP1$dic$dic, 
                inlaZINB1$dic$dic)) %>%
  arrange(WAIC) %>%
  kable(digits = 3)
```

Het Poisson model is opnieuw het simpelste model met de beste fit. We controleren voor overdispersie (waarom hier onderdispersie?):

```{r}
plot(dispersion_check(inlapois1))
```

Er zijn iets meer waargenomen nullen dan verwacht onder het model:

```{r}
plot(fast_distribution_check(inlapois1))
```

**Resultaten en visualisatie**

Samenvatting van coefficienten:

```{r}
inlapois1$summary.fixed %>%
  select(1, lcl = 3, ucl = 5) %>%
  kable(digits = 5)
```

Visualisatie:

```{r}
# Create data to predict and add to data
newdata <- expand.grid(regio = unique(gele_kwik_2022$regio),
                       periode_in_jaar = unique(gele_kwik_2022$periode_in_jaar))

data_pred <- rbind(gele_kwik_2022, newdata)

# Fit model and add predictions to new dataframe
inlapois1_pred <- inla(aantal ~ regio + periode_in_jaar + f(plotnaam, model = "iid"), 
             data = data_pred, family = "poisson",
             control.family = list(link = "log"),
             control.predictor = list(link = 1, compute = TRUE),
             control.compute = list(waic = TRUE, config = TRUE))

newdata <- cbind(newdata,
  inlapois1_pred$summary.fitted.values[(nrow(gele_kwik_2022) + 1):nrow(data_pred),])

# Visualise
p_inlapois1 <- newdata %>%
  rename("lower" = "0.025quant", upper = "0.975quant") %>%
  ggplot(aes(y = mean, x = regio)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lower, ymax = upper, colour = periode_in_jaar), 
                width = 0.25, position = position_dodge(width = 0.5)) +
  scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
                  name = "Aantal broedparen Gele kwikstaart per 100 ha"), 
                  limits = c(0, 0.4)) +
  labs(x = "", y = "", title = "INLA package") +
                theme(legend.position = "bottom")

p_pois1_new <- plot(pred, plot = FALSE)[[1]] + 
                  scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
                    name = ""), limits = c(0, 0.4)) +
                  labs(y = "Aantal broedparen Gele kwikstaart per plot", x = "", 
                       title = "brms package") +
                  theme(legend.position = "bottom")

grid.arrange(p_pois1_new, p_inlapois1, ncol = 2)
```

We krijgen quasi dezelfde resultaten als met **brms**.


### STAN{#STAN}

**Op verkenning**

Dit is als oefening/voorbereiding op meer complexe analyses verderop. Kunnen we de resultaten van **brms** repliceren met deze STAN?

Handige links:
https://gist.github.com/mbjoseph/2eb323610ea10e848a5b1d41377b141b  

Je kan van **brms** naar STAN gaan  met functies `make_stancode()` en `make_standata()`.

```{r}
stan_models <- here("src", "markdown", "mas", "stan_models")

stan_data <- make_standata(
  bf(aantal ~ regio + periode_in_jaar + (1 | plotnaam)), 
  data = gele_kwik_2022, family = poisson()
  )
```

We fitten het model aan de data en controleren convergentie.

```{r}
# Retrieve stan model
path_stan_pois <- paste(stan_models, "glmm_pois.stan", sep = "/")

# Fit model
stan_pois <- stan(path_stan_pois, data = stan_data, iter = niter, 
                  warmup = burnin, chains = nchains, cores = nparallel, 
                  seed = 1235)

# Check convergence first 10 parameters
traceplot(stan_pois)
```

We zien dat de parameters inderdaad gelijkaardig zijn als voordien:

```{r}
summary(stan_pois, pars = c("b", "Intercept"), 
        probs = c(0.025, 0.50, 0.975))$summary %>%
  as.data.frame() %>%
  rownames_to_column(var = "param") %>%
  mutate(param = recode(param, 
                        "b[1]" = "regioOostelijkeleemstreek",
                        "b[2]" = "periode_in_jaarR2",
                        "b[3]" = "periode_in_jaarR3",
                        "b[4]" = "periode_in_jaarR4")) %>%
  kable(digits = 4)
```


## Distance sampling{#dist-samp}
### Distance package{#Distance}

**Op verkenning**

In de GLMM's houden we echter geen rekening met een afnemende detectiekans naarmate de dieren zich verder bevinden. De logica achter distance sampling is uitgebreider uitgelegd in \@ref(dist-terr). In \@ref(GLMM) hadden we de data geaggregeerd per telcirkel per telperiode, in deze sectie werken we met de directe observaties: waarnemingen van $n$ aantal broedparen Gele kwikstaart op een afstand van $x$ meter van het telpunt per telperiode in 2022.

Handige links:  
https://www.jstatsoft.org/article/download/v089i01/1288  


```{r data-dist}
gele_kwik_2022_distance <- gele_kwik_2022_presences %>%
  # Add absences
  full_join(bezoekenlijst_2022, by = c("plotnaam", "periode_in_jaar", "regio", 
                                       "stratum", "openheid", "sbp")) %>%
  # Replace NA's by 0's
  mutate(aantal = ifelse(is.na(aantal), 0, aantal)) %>%
  arrange(plotnaam, periode_in_jaar)

reg_tab <- perimeters %>% mutate(Area = as.numeric(st_area(geom)) / 1e6) %>%
            select(Naam, Area) %>%
            rename(regio = Naam) %>%
            st_drop_geometry()

conversion_factor <- convert_units("meter", NULL, "Square kilometer")
```

Wat is de verdeling van de geregistreerde afstanden? Afstanden van absences zijn `NA`.

```{r tabel-dist}
gele_kwik_2022_distance %>%
  group_by(regio, periode_in_jaar) %>%
  summarise(min = min(distance2plot, na.rm = TRUE), 
            mediaan = median(distance2plot, na.rm = TRUE),
            gemiddelde = mean(distance2plot, na.rm = TRUE),
            max = max(distance2plot, na.rm = TRUE),
            varantie = var(distance2plot, na.rm = TRUE)) %>%
  kable(digits = 1)
```

```{r histogram-dist}
gele_kwik_2022_distance %>%
  filter(!is.na(distance2plot)) %>%
  ggplot() +
    geom_histogram(aes(x = distance2plot, fill = periode_in_jaar), bins = 30) +
    facet_wrap(~regio) +
    labs(y = "Aantal", x = "Afstand (m)")
```

```{r histogram-dist-stratum}
gele_kwik_2022_distance %>%
  filter(!is.na(distance2plot)) %>%
  ggplot() +
    geom_histogram(aes(x = distance2plot, fill = stratum), bins = 30) +
    facet_wrap(~regio) +
    labs(y = "Aantal", x = "Afstand (m)")
```

**Data voorbereiden**

De dataframe moet een kolom met de naam `distance` bevatten (met de waargenomen afstanden) en extra benoemde kolommen voor eventuele covariaten die de detecteerbaarheid kunnen beÃ¯nvloeden (bijvoorbeeld waarnemer effect of visibiliteit). Om de densiteit te schatten of de abundantie, is aanvullende informatie vereist. Extra kolommen moeten worden opgenomen de dataframe met vermelding van: `Sample.Label` (ID van het transect/plot), `Effort` (het aantal keren dat dat punt is bezocht); `Region.Label` (het stratum dat het transect bevat) en `Area` (de oppervlakte van de strata). Transecten/plots die zijn onderzocht maar geen waarnemingen hebben, moeten worden opgenomen in de dataset met `NA` voor afstand en eventuele andere covariaten. De kolom `size`geeft de cluster groottes aan zodat elke rij een observatie van een cluster/groep is in plaats van een individu.

```{r dist-dataframe}
gele_kwik_2022_ds <- gele_kwik_2022_distance %>%
  select(plotnaam, regio, periode_in_jaar, aantal, distance2plot, 
         openheid, sbp) %>%
  full_join(reg_tab, by = "regio") %>% 
  rename(Sample.Label = plotnaam, size = aantal, distance = distance2plot) %>%
  mutate(Region.Label = paste(regio, periode_in_jaar, sep = " - ")) %>%
  group_by(Sample.Label) %>%
  mutate(Effort = 1)
```

**Model selectie en fit**

We fitten 3 verschillende detectiefuncties die we laten afhangen van covariaten regio en telperiode. Voor de uniforme verdeling kunnen geen covariaten worden toegevoegd.

- Fitting uniform key function

```{r uniform-ds}
dsmodelunif1 <- ds(data = gele_kwik_2022_ds, key = "unif", truncation = 300, 
                 transect = "point", dht_group = FALSE,
                 convert_units = conversion_factor)
```

- Fitting half-normal key function

```{r halfnormal-ds}
dsmodelhn1 <- ds(data = gele_kwik_2022_ds, key = "hn", truncation = 300, 
                 transect = "point", dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn2 <- ds(data = gele_kwik_2022_ds, key = "hn", formula = ~ regio,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn3 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn4 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ regio + periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn5 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ regio + periode_in_jaar + 
                   regio:periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)
```

- Fitting hazard-rate key function

```{r hazard-rate-ds}
dsmodelhr1 <- ds(data = gele_kwik_2022_ds, key = "hr", truncation = 300, 
                 transect = "point", dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr2 <- ds(data = gele_kwik_2022_ds, key = "hr", formula = ~ regio,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr3 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr4 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ regio + periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr5 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ regio + periode_in_jaar + 
                   regio:periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)
```

We bekijken model fit m.b.v. QQ-plots en probability density function plots. Voor punttransectstudies geven probability density function plots een beter idee van modelfit dan de detectiefunctieplots. Dit komt omdat bij het plotten van de detectiefunctie voor punttransectgegevens, de histogram opnieuw moet worden geschaald om rekening te houden met de geometrie van de punt. Punten op de plot geven de kans op detectie voor elke waarneming aan.

```{r model-fit-ds}
par(mfrow = c(1, 2))

# Uniform model
gof_ds(dsmodelunif1, main = "dsmodelunif1")
plot(dsmodelunif1, pdf = TRUE, 
     main = paste0("dsmodelunif1 - ", "AIC: ", 
                   as.character(round(summary(dsmodelunif1)$ds$aic, digits = 2))
                   )
     )

# Half-normal models
for (i in 1:5) {
  mod <- get(paste0("dsmodelhn", i))
  name <- paste0("dsmodelhn", i)
  
  gof_ds(mod, main = name)
  
  plot(mod, pdf = TRUE, 
       main = paste0(name, " - ", "AIC: ",
                     as.character(round(summary(mod)$ds$aic, digits = 2))
                     )
       )
}

# Hazard-rate models
for (i in 1:5) {
  mod <- get(paste0("dsmodelhr", i))
  name <- paste0("dsmodelhr", i)
  
  gof_ds(mod, main = name)
  
  plot(mod, pdf = TRUE, 
       main = paste0(name, " - ", "AIC: ",
                     as.character(round(summary(mod)$ds$aic, digits = 2))
                     )
       )
}

par(mfrow = c(1, 1))
```

We vergelijken de AIC van de verschillende modellen. Als het verschil tussen AIC's kleiner is dan 2, kiezen we het eenvoudigste van deze modellen. Modellen met vergelijkbare AIC's hebben vergelijkbare geschatte detectiekansen,
dus in de praktijk is er weinig verschil in de keuze tussen deze modellen.

```{r model-comparisons-ds}
summarize_ds_models(dsmodelunif1, 
                    dsmodelhn1, dsmodelhn2, dsmodelhn3, 
                    dsmodelhn4, dsmodelhn5, 
                    dsmodelhr1, dsmodelhr2, dsmodelhr3, 
                    dsmodelhr4, dsmodelhr5) %>%
  kable()
```

**Resultaten en visualisatie**

Op basis van deze redenering kiezen we voor model 7 met de Hazard-rate functie en zonder covariaten. Dit model geeft de volgende detectiekans:

```{r final-model-summary-ds}
summary_hr1 <- summary(dsmodelhr1)
summary_hr1$ds$coeff$key.scale %>%
  kable(digits = 2)

plot(dsmodelhr1)
```

De schattingen van abundantie (totaal aantal broedparen voor de volledige regio) en voor densiteit (aantal broedparen per 100 ha):

```{r visualise-final-model-ds}
summary_results <- bind_rows(
  summary_hr1$dht$clusters$D %>%
    mutate(variable = "density",
           type = "clusters"),
  summary_hr1$dht$clusters$N %>%
    mutate(variable = "abundance",
           type = "clusters"),
  summary_hr1$dht$individuals$D %>%
    mutate(variable = "density",
           type = "individuals"),
  summary_hr1$dht$individuals$N %>%
    mutate(variable = "abundance",
           type = "individuals")
  ) %>%
  as_tibble() %>%
  separate(Label, c("regio", "periode_in_jaar"), sep = " - ") %>%
  filter(!is.na(periode_in_jaar))

summary_results %>%
  filter(type == "individuals") %>%
  mutate(variable = recode_factor(variable, 
            abundance = "Totaal aantal broedparen Gele kwikstaart",
            density = "Aantal broedparen Gele kwikstaart per 100 ha")) %>%
  ggplot(aes(x = regio, y = Estimate)) + 
  geom_pointrange(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar),
                  position = position_dodge(width = 0.5)) + 
  facet_wrap(~variable, scales = "free_y") +
  labs(x = "", y = "")
```

We kunnen vergelijken met de vorige resultaten waarbij we geen detectiekans in beschouwing namen:

```{r visualise-final-model-comparison}
# GLMM model met brms package
GLMM_preds <- pred$`regio:periode_in_jaar` %>%
  select(regio, periode_in_jaar, estimate__, lower__, upper__) %>%
  mutate(across(.cols = is.numeric, .fns = function(i) {i / cirkelopp * 1e6}))

GLMM_model <- GLMM_preds %>%
  ggplot(aes(x = regio, y = estimate__)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lower__, ymax = upper__, colour = periode_in_jaar), 
                  width = 0.25, position = position_dodge(width = 0.5)) + 
    scale_y_continuous(breaks = seq(0, 11, 1), limits = c(0, 11)) +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart per 100 ha", 
         title = "GLMM (brms)") +
    theme(legend.position = "bottom")


# Distance model rekening houdend met detectiekans
dist_model <- summary_results %>%
  filter(type == "individuals", variable == "density") %>%
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar), 
                  width = 0.25, position = position_dodge(width = 0.5)) + 
    scale_y_continuous(breaks = seq(0, 11, 1), limits = c(0, 11)) +
    labs(x = "", y = "", title = "Distance sampling (Distance)") +
    theme(legend.position = "bottom")

grid.arrange(GLMM_model, dist_model, ncol = 2)
```

De schattingen van densiteit liggen duidelijk hoger dan bij de analyse waarbij we geen rekening hielden met detectiekans. De relatieve verschillen tussen de jaren en regioâs blijven min of meer dezelfde. Bij distance sampling hebben we wel verschillende trends over telperiodes tussen regio's. Dit laatste hebben we niet opgenomen in het GLMM (geen interactieterm). Ook was de densiteit lager in de Oostelijke leemstreek dan De Moeren in het GLMM terwijl we dit in het distance model niet meer zien. 

**Discussie**

Andere covariaten die invloed zouden kunnen hebben op de detectiekans zijn voorlopig niet beschouwd (ervaring teller, visibiliteit, uur na zonsopkomst ...?).  

We kunnen de afstanden ook in categorieÃ«n opsplitsen. bijvoorbeeld 0-100, 100-200 en 200-300. Dit is mogelijks een meer robuuste methode. Met de optie `cutpoints` in de `ds()` functie is dit eenvoudig toe te passen.

- Fitting uniform key function

```{r uniform-ds-binned}
# Set max adjustments to 2 otherwise not enough degrees of freedom
dsmodelunif1_binned <- ds(data = gele_kwik_2022_ds, key = "unif", 
                 truncation = 300, cutpoints = c(0, 100, 200, 300),
                 transect = "point", dht_group = FALSE,
                 convert_units = conversion_factor, max_adjustments = 2)
```

- Fitting half-normal key function

```{r halfnormal-ds-binned}
dsmodelhn1_binned <- ds(data = gele_kwik_2022_ds, key = "hn", truncation = 300, 
                 transect = "point", dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhn2_binned <- ds(data = gele_kwik_2022_ds, key = "hn", formula = ~ regio,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhn3_binned <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhn4_binned <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ regio + periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhn5_binned <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ regio + periode_in_jaar + 
                   regio:periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))
```

- Fitting hazard-rate key function

```{r hazard-rate-ds-binned}
dsmodelhr1_binned <- ds(data = gele_kwik_2022_ds, key = "hr", truncation = 300, 
                 transect = "point", dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhr2_binned <- ds(data = gele_kwik_2022_ds, key = "hr", formula = ~ regio,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhr3_binned <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhr4_binned <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ regio + periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))

dsmodelhr5_binned <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ regio + periode_in_jaar + 
                   regio:periode_in_jaar,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor, 
                 cutpoints = c(0, 100, 200, 300))
```

We vergelijken de AIC van de verschillende modellen. Als het verschil tussen AICâs kleiner is dan 2, kiezen we het eenvoudigste van deze modellen. Modellen met vergelijkbare AICâs hebben vergelijkbare geschatte detectiekansen, dus in de praktijk is er weinig verschil in de keuze tussen deze modellen.

```{r model-comparisons-ds-binned}
summarize_ds_models(dsmodelunif1_binned, 
                    dsmodelhn1_binned, dsmodelhn2_binned, dsmodelhn3_binned, 
                    dsmodelhn4_binned, dsmodelhn5_binned, 
                    dsmodelhr1_binned, dsmodelhr2_binned, dsmodelhr3_binned, 
                    dsmodelhr4_binned, dsmodelhr5_binned) %>% 
  kable()
```

We zien dat de eenvoudigste modellen dicht bij elkaar liggen op vlak van AIC. We vergelijken model fit. Er zijn niet genoeg vrijheidsgraden voor de goodness-of-fit test.

```{r model-fit-ds-binned}
par(mfrow = c(1, 2))

# Uniform model
plot(dsmodelunif1_binned)
plot(dsmodelunif1_binned, pdf = TRUE, 
     main = paste0("dsmodelunif1_binned - ", "AIC: ", 
                   as.character(round(summary(dsmodelunif1_binned)$ds$aic, 
                                      digits = 2))
                   )
     )

# Half-normal model
plot(dsmodelhn1_binned)
plot(dsmodelhn1_binned, pdf = TRUE, 
     main = paste0("dsmodelhn1_binned - ", "AIC: ", 
                   as.character(round(summary(dsmodelhn1_binned)$ds$aic, 
                                      digits = 2))
                   )
     )

# Hazard-ratio model
plot(dsmodelhr1_binned)
plot(dsmodelhr1_binned, pdf = TRUE, 
     main = paste0("dsmodelhr1_binned - ", "AIC: ", 
                   as.character(round(summary(dsmodelhr1_binned)$ds$aic, 
                                      digits = 2))
                   )
     )

par(mfrow = c(1, 1))
```

Op basis van model fit kiezen we opnieuw voor model 7 met de Hazard-rate functie en zonder covariaten. Dit model geeft de volgende detectiekans die gelijkaardig is als voordien:

```{r final-model-summary-ds-binned}
summary_hr1_binned <- summary(dsmodelhr1_binned)
summary_hr1_binned$ds$coeff$key.scale %>%
  kable(digits = 2)
```

We vergelijken de schattingen tussen het continu model en het laatste model met categorische afstanden.

```{r comparison-continuous-binned}
# Create summary table
summary_results_binned <- bind_rows(
  summary_hr1_binned$dht$clusters$D %>%
    mutate(variable = "density",
           type = "clusters"),
  summary_hr1_binned$dht$clusters$N %>%
    mutate(variable = "abundance",
           type = "clusters"),
  summary_hr1_binned$dht$individuals$D %>%
    mutate(variable = "density",
           type = "individuals"),
  summary_hr1_binned$dht$individuals$N %>%
    mutate(variable = "abundance",
           type = "individuals")
  ) %>%
  as_tibble() %>%
  separate(Label, c("regio", "periode_in_jaar"), sep = " - ") %>%
  filter(!is.na(periode_in_jaar))

# Plot continuous model
dist_model2 <- summary_results %>%
  filter(type == "individuals", variable == "density") %>%
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar), 
                  width = 0.25, position = position_dodge(width = 0.5)) + 
    scale_y_continuous(breaks = seq(0, 11, 1), limits = c(0, 11)) +
    labs(x = "", y = "Aantal broedparen gele kwikstaart per 100 ha", 
         title = "Distance sampling continuous") +
    theme(legend.position = "bottom")

# Plot binned model
dist_model_binned <- summary_results_binned %>%
  filter(type == "individuals", variable == "density") %>%
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar), 
                  width = 0.25, position = position_dodge(width = 0.5)) + 
    scale_y_continuous(breaks = seq(0, 11, 1), limits = c(0, 11)) +
    labs(x = "", y = "", 
         title = "Distance sampling binned") +
    theme(legend.position = "bottom")

# Plot next to each other
grid.arrange(dist_model2, dist_model_binned, ncol = 2)
```

Er is bijna geen verschil wanneer de afstanden per 100 m worden gegroepeerd. We moeten opmerken dat het opdelen in cutpoints voorzichtig moet gebeuren. Hier zagen we in de continue distance functie dat de detectiekans tot 100 meter 1 is en daarna sterk daalt. Een cut-off niet rond 100 m had mogelijk een slechte keuze geweest voor de cutpoints.

**Toevoegen relevante covariaten**

Er zijn nog andere variabelen die ook een invloed op de detectiekans kunnen hebben. Deze zijn in ons geval de openheid van het landschap en buiten of binnen soortbeschermingsplan. We fitten verschillende cominaties. De interactie tussen regio en openheid kan niet gefit worden (geen HOL in De Moeren).  

- Fitting half-normal key function

```{r}
dsmodelhn6 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ sbp,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn7 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn8 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ regio + sbp + regio:sbp,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn9 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ sbp + openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn10 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ sbp + openheid + sbp:openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhn11 <- ds(data = gele_kwik_2022_ds, key = "hn", 
                 formula = ~ sbp + regio + openheid + regio:sbp,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)
```

- Fitting hazard-rate key function

```{r}
dsmodelhr6 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ sbp,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr7 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr8 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ regio + sbp + regio:sbp,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr9 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ sbp + openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr10 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ sbp + openheid + sbp:openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)

dsmodelhr11 <- ds(data = gele_kwik_2022_ds, key = "hr", 
                 formula = ~ sbp + regio + openheid + regio:sbp,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE,
                 convert_units = conversion_factor)
```

We vergelijken de AIC van de verschillende modellen. Als het verschil tussen AICâs kleiner is dan 2, kiezen we het eenvoudigste van deze modellen. We kiezen we voor model 20 met de Hazard-rate functie waarbij de detectiekans afhankelijk is van soortbeschermingsplan per regio. 

```{r}
summarize_ds_models(dsmodelunif1, 
                    dsmodelhn1, dsmodelhn2, dsmodelhn3, 
                    dsmodelhn4, dsmodelhn5, dsmodelhn6, dsmodelhn7, 
                    dsmodelhn8, dsmodelhn9, dsmodelhn10, dsmodelhn11,
                    dsmodelhr1, dsmodelhr2, dsmodelhr3, 
                    dsmodelhr4, dsmodelhr5, dsmodelhr6, dsmodelhr7, 
                    dsmodelhr8, dsmodelhr9, dsmodelhr10, dsmodelhr11) %>%
  kable()
```

Model fit:

```{r}
par(mfrow = c(1, 2))
gof_ds(dsmodelhr8, main = "dsmodelhr8")
  
  plot(dsmodelhr8, pdf = TRUE, 
       main = paste0("dsmodelhr8", " - ", "AIC: ",
                     as.character(round(summary(dsmodelhr8)$ds$aic, digits = 2))
                     )
       )
par(mfrow = c(1, 1))
```

Resultaten:

```{r}
summary_hr8 <- summary(dsmodelhr8)
summary_hr8$ds$coeff$key.scale %>%
  kable(digits = 2)

plot(dsmodelhr8)
```

Visualisatie:

```{r}
summary_results_hr8 <- bind_rows(
  summary_hr8$dht$clusters$D %>%
    mutate(variable = "density",
           type = "clusters"),
  summary_hr8$dht$clusters$N %>%
    mutate(variable = "abundance",
           type = "clusters"),
  summary_hr8$dht$individuals$D %>%
    mutate(variable = "density",
           type = "individuals"),
  summary_hr8$dht$individuals$N %>%
    mutate(variable = "abundance",
           type = "individuals")
  ) %>%
  as_tibble() %>%
  separate(Label, c("regio", "periode_in_jaar"), sep = " - ") %>%
  filter(!is.na(periode_in_jaar))

summary_results_hr8 %>%
  filter(type == "individuals") %>%
  mutate(variable = recode_factor(variable, 
            abundance = "Totaal aantal broedparen Gele kwikstaart",
            density = "Aantal broedparen Gele kwikstaart per 100 ha")) %>%
  ggplot(aes(x = regio, y = Estimate)) + 
  geom_pointrange(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar),
                  position = position_dodge(width = 0.5)) + 
  facet_wrap(~variable, scales = "free_y") +
  labs(x = "", y = "")
```

Vergelijken met vorig model:

```{r}
# Detectiekans null model
dist_model_hr1 <- summary_results %>%
  filter(type == "individuals", variable == "density") %>%
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar), 
                  width = 0.25, position = position_dodge(width = 0.5)) + 
    scale_y_continuous(breaks = seq(0, 11, 1), limits = c(0, 11)) +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart per 100 ha", 
         title = "P(detectie) ~ 1") +
    theme(legend.position = "bottom")

# Detectiekans afhankelijk van sbp per regio
dist_model_hr8 <- summary_results_hr8 %>%
  filter(type == "individuals", variable == "density") %>%
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lcl, ymax = ucl, colour = periode_in_jaar), 
                  width = 0.25, position = position_dodge(width = 0.5)) + 
    scale_y_continuous(breaks = seq(0, 11, 1), limits = c(0, 11)) +
    labs(x = "", y = "", 
         title = "P(detectie) ~ sbp + regio + sbp:regio") +
    theme(legend.position = "bottom")


grid.arrange(dist_model_hr1, dist_model_hr8, ncol = 2)
```

We zien kleine verschillen. Vooral in De Moeren wel iets lager met covariaten.


### unmarked package{#unmarked}

**Op verkenning**

In **Distance** deden we aan zgn. Conventional distance sampling (CDS) waarbij de afstanden werden gebundeld voor alle ruimtelijke locaties (i.c. plots) om de parameter(s) van de detectiefunctie te schatten, bijvoorbeeld \sigma voor de half-normaale functie. Dit wordt gebruikt om een schatting van de dichtheid te verkrijgen, en vervolgens wordt de variantie gebaseerd op de variantie van de "encounter rate", die wel enige informatie uit de plots gebruikt. Bij CDS wordt er ook uitgegaan dat dieren uniform worden verdeeld met betrekking tot transecten/telpunten en vereisen dus gerandomiseerde plaatsing van transecten/punten tijdens het steekproefdesign. Hierbij worden factoren die de abundantie tussen plots beÃ¯nvloeden verwaarloosd. De logica achter distance sampling is uitgebreider uitgelegd in \@ref(dist-terr). In de **unmarked** package kunnen we het zgn. Hierarchical distance sampling (HDS) toepassen. Dit zijn parametrisch modellen om variatie in abundantie tussen plots te beschrijven. In plaats van gegevens te bundelen als bij CDS, biedt HDS een expliciet model voor de variatie van de lokale populatiegrootte $N_i$ (de abundantie voor plot $i$). Door een model voor deze latente variabele specificeren, kunnen we dan expliciete modellen bouwen voor distance sampling data die verantwoordelijk zijn voor variatie in abundatie (of lokale dichtheid) tussen steekproefeenheden (plots), waardoor inferentie over factoren die ruimtelijke invloed hebben op variatie in abundatie wordt vergemakkelijkt alsook expliciete spatiale predicties over abundantie.

Handige links:  
https://cran.r-project.org/web/packages/unmarked/vignettes/distsamp.html  
https://www.rdocumentation.org/packages/unmarked/versions/1.2.5/topics/gdistsamp  
https://rstudio-pubs-static.s3.amazonaws.com/221408_23c61679859e48e6bae0b9c5c2e48a92.html  

Zie ook hoofdstuk 8.4.2. in het boek van KÃ©ry en Royle (2015).

**Data voorbereiden**

We converteren de gegevens naar gegevens op plotniveau met behulp van de functie `formatDistData()`. Dit creÃ«ert een object dat tellingen bevat voor elke plot (rij) in elk afstandsinterval (kolommen). Het is belangrijk dat alle onderzochte plots in de analyse worden opgenomen, ook als er geen individuen zijn gedetecteerd.

```{r}
# Plotnamen en telperiodes als factor
gele_kwik_2022_ds2 <- gele_kwik_2022_ds %>% 
  mutate(Sample.Label = as.factor(Sample.Label),
         periode_in_jaar = as.factor(periode_in_jaar)) %>%
  arrange(Sample.Label)

# Dupliceer rijen volgens aantal (elke rij is 1 individu)
# Dataframe noodzakelijk voor volgende stap
gele_kwik_2022_ds2 <- 
  data.frame(
    gele_kwik_2022_ds2[rep(seq_len(dim(gele_kwik_2022_ds2)[1]), 
                  gele_kwik_2022_ds2$size), , 
                  drop = FALSE], 
    row.names = NULL
  )

# Converteer naar format voor distsamp()/gdistsamp() functies
# We splitsen de afstanden per 100 m
gele_kwik_2022_unmarked <- formatDistData(distData = gele_kwik_2022_ds2, 
                                          distCol = "distance", 
                                          transectNameCol = "Sample.Label", 
                                          dist.breaks = c(0, 100, 200, 300))
```

Als plot-specifieke covariaten beschouwen we regio (De Moeren of Oostelijke leemstreek), openheid (HOL of OL) en sbp (binnen of buiten). De functie `unmarkedFrameDS()` kan daarna worden gebruikt om deze gegevens samen met hun metagegevens (studieontwerp (punt-transect), breekpunten van afstandsklassen en meeteenheden) te ordenen in een object dat als het gegevensargument moet worden gebruikt in `distsamp()`/`gdistsamp()`. Door de gegevens op deze manier te organiseren,moeten we deze argumenten niet herhaaldelijk opgeven tijdens elke aanroep van `distsamp()`/`gdistsamp()`, waardoor de kans op fouten wordt verkleind en de samenvatting en manipulatie van gegevens wordt vergemakkelijkt.

```{r}
covs_unmarked <- gele_kwik_2022 %>%
  ungroup() %>%
  distinct(plotnaam, regio, openheid, sbp) %>%
  mutate(across(.cols = everything(), as.factor)) %>%
  arrange(plotnaam)

umf <- unmarkedFrameDS(y = as.matrix(gele_kwik_2022_unmarked), 
                       siteCovs = covs_unmarked, survey = "point",
                       dist.breaks = c(0, 100, 200, 300),
                       unitsIn = "m")

summary(umf)

hist(umf, xlab = "Distance (m)", main = "", las = 1)
```

**Model selectie en fit**

Op basis van eerdere resultaten en bovenstaande histogram zullen we de uniforme detectiefuctie niet beschouwen. Deze past namelijk goed als het aantal tellingen niet afneemt over de afstand, wat duidelijk wel het geval is. Ook de exponentiele functie wordt niet beschouwd (zelfs voor meest simpele model: `Warning message:Hessian is singular. Try providing starting values or using fewer covariates.`).

We testen null modellen en modellen met regio in combinatie met openheid en sbp.

```{r, cache=TRUE}
# Null modellen
um_model_hn1 <- distsamp(formula = ~1~1, data = umf, keyfun = "halfnorm", 
                         output = "density",
         unitsOut = "kmsq")
um_model_hr1 <- distsamp(formula = ~1~1, data = umf, keyfun = "hazard", 
                         output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio
um_model_hn2 <- distsamp(formula = ~regio~1, data = umf, keyfun = "halfnorm", 
                         output = "density",
         unitsOut = "kmsq")
um_model_hr2 <- distsamp(formula = ~regio~1, data = umf, keyfun = "hazard", 
                         output = "density",
         unitsOut = "kmsq")

# Densiteit verschilt per regio
um_model_hn3 <- distsamp(formula = ~1~regio, data = umf, keyfun = "halfnorm", 
                         output = "density",
         unitsOut = "kmsq")
um_model_hr3 <- distsamp(formula = ~1~regio, data = umf, keyfun = "hazard", 
                         output = "density",
         unitsOut = "kmsq")

# Detectiekans en densiteit verschillen per regio
um_model_hn4 <- distsamp(formula = ~regio~regio, data = umf, keyfun = "halfnorm", 
                         output = "density",
         unitsOut = "kmsq")
um_model_hr4 <- distsamp(formula = ~regio~regio, data = umf, keyfun = "hazard", 
                         output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio en openheid landschap
um_model_hn5 <- distsamp(formula = ~regio + openheid~1, data = umf, 
                         keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr5 <- distsamp(formula = ~regio + openheid~1, data = umf, 
                         keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Densiteit verschilt per regio en openheid landschap
um_model_hn6 <- distsamp(formula = ~1~regio + openheid, data = umf, 
                         keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr6 <- distsamp(formula = ~1~regio + openheid, data = umf, 
                         keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans en densiteit verschillen per regio en openheid landschap
um_model_hn7 <- distsamp(formula = ~regio + openheid~regio + openheid, 
                         data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr7 <- distsamp(formula = ~regio + openheid~regio + openheid, 
                         data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio en soortbeschermingsplan
um_model_hn8 <- distsamp(formula = ~regio + sbp~1, data = umf, 
                         keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr8 <- distsamp(formula = ~regio + sbp~1, data = umf, 
                         keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Densiteit verschilt per regio en soortbeschermingsplan
um_model_hn9 <- distsamp(formula = ~1~regio + sbp, data = umf, 
                         keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr9 <- distsamp(formula = ~1~regio + sbp, data = umf, 
                         keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans en densiteit verschillen per regio en soortbeschermingsplan
um_model_hn10 <- distsamp(formula = ~regio + sbp~regio + sbp, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr10 <- distsamp(formula = ~regio + sbp~regio + sbp, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio en soortbeschermingsplan
# en openheid landschap
um_model_hn11 <- distsamp(formula = ~regio + sbp + openheid~1, data = umf, 
                         keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr11 <- distsamp(formula = ~regio + sbp + openheid~1, data = umf, 
                         keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Densiteit verschilt per regio en soortbeschermingsplan
# en openheid landschap
um_model_hn12 <- distsamp(formula = ~1~regio + sbp + openheid, data = umf, 
                         keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr12 <- distsamp(formula = ~1~regio + sbp + openheid, data = umf, 
                         keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans en densiteit verschillen per regio en soortbeschermingsplan
# en openheid landschap
um_model_hn13 <- distsamp(
  formula = ~regio + sbp + openheid~regio + sbp + openheid, 
  data = umf, keyfun = "halfnorm", output = "density", unitsOut = "kmsq")
um_model_hr13 <- distsamp(
  formula = ~regio + sbp + openheid~regio + sbp + openheid, 
  data = umf, keyfun = "hazard", output = "density", unitsOut = "kmsq")
```

Het half-normal model waarbij zowel detectiekans als densiteit verschilt per regio, soortbeschermingsplan en openheid landschap scoort het best.

```{r}
fm_list <- fitList(hn1 = um_model_hn1, hn2 = um_model_hn2, hn3 = um_model_hn3,
                   hn4 = um_model_hn4, hn5 = um_model_hn5, hn6 = um_model_hn6,
                   hn7 = um_model_hn7, hn8 = um_model_hn8, hn9 = um_model_hn9, 
                   hn10 = um_model_hn10,
                   hn11 = um_model_hn11, hn12 = um_model_hn12, 
                   hn13 = um_model_hn13,
                   hr1 = um_model_hr1, hr2 = um_model_hr2, hr3 = um_model_hr3,
                   hr4 = um_model_hr4, hr5 = um_model_hr5, hr6 = um_model_hr6,
                   hr7 = um_model_hr7, hr8 = um_model_hr8, hr9 = um_model_hr9, 
                   hr10 = um_model_hr10,
                   hr11 = um_model_hr11, hr12 = um_model_hr12, 
                   hr13 = um_model_hr13)
modSel(fm_list)
```

We testen nu modellen waarbij we elk van de factoren Ã©Ã©n voor Ã©Ã©n weglaten.

```{r, cache=TRUE}
# Detectiekans verschilt per regio en soortbeschermingsplan
# Densiteit verschilt per regio, soortbeschermingsplan en openheid landschap
um_model_hn14 <- distsamp(formula = ~regio + sbp~regio + sbp + openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr14 <- distsamp(formula = ~regio + sbp~regio + sbp + openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio, soortbeschermingsplan en openheid landschap
# Densiteit verschilt per regio en soortbeschermingsplan
um_model_hn15 <- distsamp(formula = ~regio + sbp + openheid~regio + sbp, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr15 <- distsamp(formula = ~regio + sbp + openheid~regio + sbp, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio en openheid landschap
# Densiteit verschilt per regio en openheid landschap
um_model_hn16 <- distsamp(formula = ~regio + openheid~regio + openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr16 <- distsamp(formula = ~regio + openheid~regio + openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per regio, soortbeschermingsplan en openheid landschap
um_model_hn17 <- distsamp(formula = ~sbp~regio + sbp + openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr17 <- distsamp(formula = ~sbp~regio + sbp + openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per regio en soortbeschermingsplan
# Densiteit verschilt per soortbeschermingsplan en openheid landschap
um_model_hn18 <- distsamp(formula = ~regio + sbp~sbp + openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr18 <- distsamp(formula = ~regio + sbp~sbp + openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")
```

Het half-normal model waarbij detectiekans verschilt per soortbeschermingsplan en densiteit verschilt per regio, soortbeschermingsplan en openheid landschap scoort het best (eenvoudigst model met verschil in AIC < 2)

```{r}
fm_list <- fitList(hn1 = um_model_hn1, hn2 = um_model_hn2, hn3 = um_model_hn3,
                   hn4 = um_model_hn4, hn5 = um_model_hn5, hn6 = um_model_hn6,
                   hn7 = um_model_hn7, hn8 = um_model_hn8, hn9 = um_model_hn9, 
                   hn10 = um_model_hn10,
                   hn11 = um_model_hn11, hn12 = um_model_hn12, 
                   hn13 = um_model_hn13,
                   hn14 = um_model_hn14, hn15 = um_model_hn15,
                   hn16 = um_model_hn16, hn17 = um_model_hn17,
                   hn18 = um_model_hn18,
                   hr1 = um_model_hr1, hr2 = um_model_hr2, hr3 = um_model_hr3,
                   hr4 = um_model_hr4, hr5 = um_model_hr5, hr6 = um_model_hr6,
                   hr7 = um_model_hr7, hr8 = um_model_hr8, hr9 = um_model_hr9, 
                   hr10 = um_model_hr10,
                   hr11 = um_model_hr11, hr12 = um_model_hr12, 
                   hr13 = um_model_hr13,
                   hr14 = um_model_hr14, hr15 = um_model_hr15,
                   hr16 = um_model_hr16, hr17 = um_model_hr17,
                   hr18 = um_model_hr18)
modSel(fm_list)
```

Detectiekans verschilt per soortbeschermingsplan, maar we testen ook nog enkele combinaties voor densiteit.

```{r, cache=TRUE}
# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per regio
um_model_hn19 <- distsamp(formula = ~sbp~regio, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr19 <- distsamp(formula = ~sbp~regio, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per soortbeschermingsplan
um_model_hn20 <- distsamp(formula = ~sbp~sbp, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr20 <- distsamp(formula = ~sbp~sbp, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per openheid landschap
um_model_hn21 <- distsamp(formula = ~sbp~openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr21 <- distsamp(formula = ~sbp~openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per regio en soortbeschermingsplan
um_model_hn22 <- distsamp(formula = ~sbp~regio + sbp, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr22 <- distsamp(formula = ~sbp~regio + sbp, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per regio en openheid landschap
um_model_hn23 <- distsamp(formula = ~sbp~regio + openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr23 <- distsamp(formula = ~sbp~regio + openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")
```

Het model waarbij detectiekans verschilt per soortbeschermingsplan en densiteit verschilt per openheid landschap scoort het best.

```{r}
fm_list <- fitList(hn1 = um_model_hn1, hn2 = um_model_hn2, hn3 = um_model_hn3,
                   hn4 = um_model_hn4, hn5 = um_model_hn5, hn6 = um_model_hn6,
                   hn7 = um_model_hn7, hn8 = um_model_hn8, hn9 = um_model_hn9, 
                   hn10 = um_model_hn10,
                   hn11 = um_model_hn11, hn12 = um_model_hn12, 
                   hn13 = um_model_hn13,
                   hn14 = um_model_hn14, hn15 = um_model_hn15,
                   hn16 = um_model_hn16, hn17 = um_model_hn17,
                   hn18 = um_model_hn18,
                   hn19 = um_model_hn19, hn20 = um_model_hn20,
                   hn21 = um_model_hn21, hn22 = um_model_hn22,
                   hn23 = um_model_hn23,
                   hr1 = um_model_hr1, hr2 = um_model_hr2, hr3 = um_model_hr3,
                   hr4 = um_model_hr4, hr5 = um_model_hr5, hr6 = um_model_hr6,
                   hr7 = um_model_hr7, hr8 = um_model_hr8, hr9 = um_model_hr9, 
                   hr10 = um_model_hr10,
                   hr11 = um_model_hr11, hr12 = um_model_hr12, 
                   hr13 = um_model_hr13,
                   hr14 = um_model_hr14, hr15 = um_model_hr15,
                   hr16 = um_model_hr16, hr17 = um_model_hr17,
                   hr18 = um_model_hr18,
                   hr19 = um_model_hr19, hr20 = um_model_hr20,
                   hr21 = um_model_hr21, hr22 = um_model_hr22,
                   hr23 = um_model_hr23)
modSel(fm_list)
```

Als laatste testen we of we het model eenvoudiger kan of als er interacties kunnen toegevoegd worden.

```{r, cache=TRUE}
# Densiteit verschilt per openheid landschap
um_model_hn24 <- distsamp(formula = ~1~openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr24 <- distsamp(formula = ~1~openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
um_model_hn25 <- distsamp(formula = ~sbp~1, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr25 <- distsamp(formula = ~sbp~1, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan in interactie met 
# openheid landschap
# Densiteit verschilt per soortbeschermingsplan in interactie met 
# openheid landschap
um_model_hn26 <- distsamp(formula = ~sbp*openheid~sbp*openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr26 <- distsamp(formula = ~sbp*openheid~sbp*openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan in interactie met regio
# Densiteit verschilt per openheid landschap in interactie met regio
um_model_hn27 <- distsamp(formula = ~sbp*regio~openheid*regio, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr27 <- distsamp(formula = ~sbp*regio~openheid*regio, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan
# Densiteit verschilt per openheid landschap in interactie met regio
um_model_hn28 <- distsamp(formula = ~sbp~openheid*regio, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr28 <- distsamp(formula = ~sbp~openheid*regio, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")

# Detectiekans verschilt per soortbeschermingsplan in interactie met regio
# Densiteit verschilt per openheid landschap
um_model_hn29 <- distsamp(formula = ~sbp*regio~openheid, 
                          data = umf, keyfun = "halfnorm", output = "density",
         unitsOut = "kmsq")
um_model_hr29 <- distsamp(formula = ~sbp*regio~openheid, 
                          data = umf, keyfun = "hazard", output = "density",
         unitsOut = "kmsq")
```

Model 21 blijft het eenvoudigste model binnen een AIC verschil van 2.

```{r}
fm_list <- fitList(hn1 = um_model_hn1, hn2 = um_model_hn2, hn3 = um_model_hn3,
                   hn4 = um_model_hn4, hn5 = um_model_hn5, hn6 = um_model_hn6,
                   hn7 = um_model_hn7, hn8 = um_model_hn8, hn9 = um_model_hn9, 
                   hn10 = um_model_hn10,
                   hn11 = um_model_hn11, hn12 = um_model_hn12, 
                   hn13 = um_model_hn13,
                   hn14 = um_model_hn14, hn15 = um_model_hn15,
                   hn16 = um_model_hn16, hn17 = um_model_hn17,
                   hn18 = um_model_hn18,
                   hn19 = um_model_hn19, hn20 = um_model_hn20,
                   hn21 = um_model_hn21, hn22 = um_model_hn22,
                   hn23 = um_model_hn23,
                   hn24 = um_model_hn24, hn25 = um_model_hn25,
                   hn26 = um_model_hn26, hn27 = um_model_hn27,
                   hn28 = um_model_hn28, hn29 = um_model_hn29,
                   hr1 = um_model_hr1, hr2 = um_model_hr2, hr3 = um_model_hr3,
                   hr4 = um_model_hr4, hr5 = um_model_hr5, hr6 = um_model_hr6,
                   hr7 = um_model_hr7, hr8 = um_model_hr8, hr9 = um_model_hr9, 
                   hr10 = um_model_hr10,
                   hr11 = um_model_hr11, hr12 = um_model_hr12, 
                   hr13 = um_model_hr13,
                   hr14 = um_model_hr14, hr15 = um_model_hr15,
                   hr16 = um_model_hr16, hr17 = um_model_hr17,
                   hr18 = um_model_hr18,
                   hr19 = um_model_hr19, hr20 = um_model_hr20,
                   hr21 = um_model_hr21, hr22 = um_model_hr22,
                   hr23 = um_model_hr23,
                   hr24 = um_model_hr24, hr25 = um_model_hr25,
                   hr26 = um_model_hr26, hr27 = um_model_hr27,
                   hr28 = um_model_hr28, hr29 = um_model_hr29)
modSel(fm_list)
```

**Resultaten en visualisatie**

Het finaal model geeft:

```{r}
# Finaal model
um_model_hn21

# Densiteit
# Half-open landschap
backTransform(linearComb(um_model_hn21["state"], c(1, 0)))

# Open landschap
backTransform(linearComb(um_model_hn21["state"], c(1, 1)))

# Detectiekans
# Binnen soortbeschermingsplan
backTransform(linearComb(um_model_hn21["det"], c(1, 0)))

# Buiten soortbeschermingsplan
backTransform(linearComb(um_model_hn21["det"], c(1, 1)))

# Predicties
new_df_dens <- expand.grid(regio = unique(covs_unmarked$regio),
                           openheid = unique(covs_unmarked$openheid))
new_df_detect <- data.frame(sbp = c("buiten", "binnen"))

Elambda <- predict(um_model_hn21, type = "state", newdata = new_df_dens,
    appendData = TRUE)
Esigma <- predict(um_model_hn21, type = "det", newdata = new_df_detect,
    appendData = TRUE)
```

We kunnen visualiseren hoe de detectiefunctie verschilt binnen en buiten de soortbeschermingsplans:

```{r}
# Detection function
plot(function(x) gxhn(x, sigma = 107.02456), 0, 300, xlab = "Afstand (m)",
    ylab = "Detection probability", las = 1, col = "blue")
plot(function(x) gxhn(x, sigma = 92.08468), 0, 300, add = TRUE, col = "green")
legend('topright', c("Binnen sbp", "Buiten sbp"),
    col = c("blue", "green"), lty = 1)
```

De schatting van de densiteiten:

```{r}
Elambda %>%
 ggplot(aes(x = openheid, y = Predicted)) + 
  geom_pointrange(aes(ymin = lower, ymax = upper, colour = regio),
                  position = position_dodge(width = 0.5)) +
  labs(colour =  "Regio", x = "Openheid landschap", 
       y = "Aantal broedparen Gele kwikstaart per 100 ha") +
  scale_y_continuous(limits = c(0, NA))
```


**Discussie**

Dit geeft echter een vreemd resultaat aangezien er in De Moeren geen plots in HOL zijn.

```{r}
design2022 %>% count(regio, openheid) %>%
  rename("aantal plots" = n) %>%
  kable()
```

<span style="color: red;">
Hoe kunnen we hiermee rekening houden? Interactie met regio werkt niet.
</span>

```{r}
# Maak predicties o.b.v. interactiemodel
Elambda_interaction <- predict(um_model_hn28, type = "state", 
                               newdata = new_df_dens, appendData = TRUE)

# Visualiseer
Elambda_interaction %>%
 ggplot(aes(x = openheid, y = Predicted)) + 
  geom_pointrange(aes(ymin = lower, ymax = upper, colour = regio),
                  position = position_dodge(width = 0.5)) +
  labs(colour =  "Regio", x = "Openheid landschap", 
       y = "Aantal broedparen Gele kwikstaart per 100 ha",
       title = "Densiteit afhankelijk van interactie regio en openheid") +
  scale_y_continuous(limits = c(0, NA))
```

We hebben geen rekening gehouden met de telperiodes. De functie `gdistsamp()` fit een meer complex model maar op welke manier hier dan met herhaalde tellingen wordt rekening gehouden is me momenteel niet duidelijk. Bovendien kan de " probability of being available for detection" geschat worden en kan een negatief binomiaal verdeling getest worden.

Voor de datapreparatie voegen we nu de optie `occasionCol`toe.

```{r}
gele_kwik_2022_unmarked2 <- formatDistData(distData = gele_kwik_2022_ds2, 
                                          distCol = "distance", 
                                          transectNameCol = "Sample.Label", 
                                          dist.breaks = c(0, 100, 200, 300),
                                          occasionCol = "periode_in_jaar")
```

Om een unmarked dataframe te maken voor `gdistsamp()` moeten we hier `unmarkedFrameGDS()` in plaats van `unmarkedFrameGDS()` in combinatie met `distsamp()`.

```{r}
umf2 <- unmarkedFrameGDS(y = as.matrix(gele_kwik_2022_unmarked2), 
                         numPrimary = 4, siteCovs = covs_unmarked, 
                         survey = "point", dist.breaks = c(0, 100, 200, 300),
                         unitsIn = "m")
```

We fitten een null model en het finaal model als hierboven zowel met een Poisson verdeling (`mixture = "P"`) als een negatief binomiaal verdeling (`mixture = "NB"`).

```{r}
um_model_GDS <- gdistsamp(~1, ~1, ~1, data = umf2, keyfun = "halfnorm", 
                  output = "density", unitsOut = "kmsq", mixture = "P")
um_model_GDS2 <- gdistsamp(~1, ~1, ~1, data = umf2, keyfun = "halfnorm", 
                   output = "density", unitsOut = "kmsq", mixture = "NB")
um_model_GDS3 <- gdistsamp(~openheid, ~1, ~sbp, data = umf2, 
                           keyfun = "halfnorm", output = "density", 
                           unitsOut = "kmsq", mixture = "P")
um_model_GDS4 <- gdistsamp(~openheid, ~1, ~sbp, data = umf2, 
                           keyfun = "halfnorm", output = "density", 
                           unitsOut = "kmsq", mixture = "NB")
```

Model selectie toont dat de negatief binomiaal verdeling optimaler is.

```{r}
fm_list2 <- fitList(um_model_GDS, um_model_GDS2, um_model_GDS3, um_model_GDS4)
modSel(fm_list2)
```

```{r}
# Finaal model
um_model_GDS4

# Densiteit
# Half-open landschap
backTransform(linearComb(um_model_GDS4["lambda"], c(1, 0)))

# Open landschap
backTransform(linearComb(um_model_GDS4["lambda"], c(1, 1)))

# Detectiekans
# Binnen soortbeschermingsplan
backTransform(linearComb(um_model_GDS4["det"], c(1, 0)))

# Buiten soortbeschermingsplan
backTransform(linearComb(um_model_GDS4["det"], c(1, 1)))

# Predicties
Elambda2 <- predict(um_model_GDS4, type = "lambda", newdata = new_df_dens,
    appendData = TRUE)
Esigma2 <- predict(um_model_GDS4, type = "det", newdata = new_df_detect,
    appendData = TRUE)
```

We kunnen visualiseren hoe de detectiefunctie verschilt binnen en buiten de soortbeschermingsplans:

```{r}
# Detection function
plot(function(x) gxhn(x, sigma = 107.21133), 0, 300, xlab = "Afstand (m)",
    ylab = "Detection probability", las = 1, col = "blue")
plot(function(x) gxhn(x, sigma = 91.76288), 0, 300, add = TRUE, col = "green")
legend('topright', c("Binnen sbp", "Buiten sbp"),
    col = c("blue", "green"), lty = 1)
```

De schatting van de densiteiten:

```{r}
Elambda2 %>%
 ggplot(aes(x = openheid, y = Predicted)) + 
  geom_pointrange(aes(ymin = lower, ymax = upper, colour = regio),
                  position = position_dodge(width = 0.5)) +
  labs(colour =  "Regio", x = "Openheid landschap", 
       y = "Aantal broedparen Gele kwikstaart per 100 ha") +
  scale_y_continuous(limits = c(0, NA))
```

Dit geeft nog steeds vreemde resultaten. We voeren een klassieke GLMM uit zoals in \@ref(brms) waarbij we nu ook de variabele 'openheid landschap' beschouwen. Het model convergeert niet bij het toevoegen van de interactie met regio (ook met 16,000 iteraties i.p.v. 4,000).

```{r}
# Voeg openheid landschap toe als variabele
brmpois_openheid1 <- brm(bf(aantal ~ regio + periode_in_jaar + openheid + 
                              (1 | plotnaam)), 
                        data = gele_kwik_2022, family = poisson(), 
                        chains = nchains, warmup = burnin, iter = niter, 
                        cores = nparallel,
                        file = paste0(model_path, "brmpois_openheid1"),
                        file_refit = "on_change")
```

Convergentie ok (scale reduction factors, trace plots, posterior density). We vergelijken de modellen gebruikmakend van 5-fold cross-validation (CV).

```{r}
# Perform K-fold cross-validation
if (!file.exists(paste0(model_path, "fit_brmpois_openheid1.rds"))) {
  fit_brmpois_openheid1 <- add_criterion(brmpois_openheid1, c("kfold"), 
                                K = 5, cores = 5,
                                folds = "stratified", group = "regio", 
                                file = paste0(model_path, 
                                              "fit_brmpois_openheid1"))
} else {
  fit_brmpois_openheid1 <- readRDS(paste0(model_path, 
                                          "fit_brmpois_openheid1.rds"))
}

# Comparison among models
comparisons_openheid <- loo_compare(fit_brmpois_openheid1, fit_brmpois1, 
                                    fit_brmnegbin1, fit_brmZIP1, 
                                    fit_brmZINB1, 
                                    criterion = "kfold")[, c(1, 2)] %>%
                as.data.frame() %>%
                mutate(model = c("Poisson: openheid", "Poisson", 
                                 "Zero-inflated Negative binomial",
                                 "Zero-inflated Poisson", "Negative binomial"))

# Tabel
rbind(fit_brmpois_openheid1$criteria$kfold$estimates[, "Estimate"],
  fit_brmpois1$criteria$kfold$estimates[, "Estimate"],
  fit_brmnegbin1$criteria$kfold$estimates[, "Estimate"],
  fit_brmZIP1$criteria$kfold$estimates[, "Estimate"], 
  fit_brmZINB1$criteria$kfold$estimates[, "Estimate"]
  ) %>%
  as.data.frame() %>%
  mutate(model = c("Poisson: openheid", models)) %>%
  full_join(comparisons_openheid, by = "model") %>%
  mutate(CI_ll = elpd_diff  + qnorm(0.025) * se_diff,
         CI_ul = elpd_diff  + qnorm(0.975) * se_diff) %>%
  select(model, everything()) %>%
  arrange(desc(elpd_diff)) %>%
  kable(digits = 3)
```

Het model scoort beter maar is niet veel beter dan het eenvoudigere model zonder openheid. Model fit is ok.

```{r}
pp_check(brmpois_openheid1, type = "bars_grouped", ndraws = 100, 
         group = "openheid",
         facet_args = list(ncol = 1, scales = "free_y"))
```

Wanneer we de resultaten visualiseren krijgen we dezelfde relatieve resultaten als bij **unmarked** package. Het is duidelijk dat de openheid van het landschap een belangrijke factor is voor het aantal broedparen van de Gele kwikstaart, maar de implementatie in de modellen moet mogelijks aangepast worden.

```{r}
pred_openheid <- conditional_effects(brmpois_openheid1, 
                                     effects = c("openheid:regio"))

plot(pred_openheid, plot = FALSE)[[1]] + 
     scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
       name = "Aantal broedparen Gele kwikstaart per 100 ha")) +
     labs(y = "Aantal broedparen Gele kwikstaart per plot", x = "")
```

Met **INLA** lukt het wel om een interactie toe te voegen. Dit levert de gewenste resultaten op.

```{r}
# Create data to predict and add to data
newdata_interaction <- expand.grid(regio = unique(gele_kwik_2022$regio),
                       periode_in_jaar = unique(gele_kwik_2022$periode_in_jaar),
                       openheid = unique(gele_kwik_2022$openheid))

data_pred_interaction <- rbind(gele_kwik_2022, newdata_interaction)

# Fit model and add predictions to new dataframe
inlapois2_pred <- inla(aantal ~ regio*openheid + periode_in_jaar + 
                         f(plotnaam, model = "iid"), 
             data = data_pred_interaction, family = "poisson",
             control.family = list(link = 'log'),
             control.predictor = list(link = 1, compute = TRUE),
             control.compute = list(waic = TRUE, config = TRUE))

newdata_interaction <- cbind(newdata_interaction,
  inlapois2_pred$summary.fitted.values[(nrow(gele_kwik_2022) + 1):nrow(data_pred_interaction),])

# Plot data
newdata_interaction %>%
  rename("lower" = "0.025quant", upper = "0.975quant") %>%
  ggplot(aes(y = mean, x = openheid)) + 
    geom_point(aes(colour = periode_in_jaar), size = 4, 
               position = position_dodge(width = 0.5)) +
    geom_errorbar(aes(ymin = lower, ymax = upper, colour = periode_in_jaar), 
                width = 0.25, position = position_dodge(width = 0.5)) +
    scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
                    name = "Aantal broedparen Gele kwikstaart per 100 ha"), 
                    limits = c(0, 0.4)) +
    labs(x = "Openheid landschap", 
         y = "Aantal broedparen Gele kwikstaart per plot") +
    facet_wrap(~regio)
```

<span style="color: red;">
Waarom werkt een interactie niet in **unmarked**??
</span>

### Hierarchical distance sampling in STAN{#HDS_STAN}

**Op verkenning**

Kunnen we de vorige resultaten repliceren in STAN?

Handige links:  
https://discourse.mc-stan.org/t/deriving-abundance-from-a-distance-sampling-model/24565/7  
https://gist.github.com/mbjoseph/960c3b259d007c81bebbaf9e5be1e250 
https://gist.github.com/mbjoseph/2eb323610ea10e848a5b1d41377b141b

***Bayesian HDS using three-part conditional multinomial model:***

We fitten een distance sampling model met gecategoriseerde afstandsdata. We gaan uit van een half-normale detectiefunctie. We berekenen de detectiekans $p_h$ voor elke afstandscategorie $h = 1, ...,H$. Beschouw de radius van de telcirkel $B$, $b_h$ de radius tot afstandscategorie $h$ en $\psi_h$ de waarschijnlijkheid dat $r$ in afstandscategorie $h$ zit, met $\psi_h = \frac{A_{h+1} - A_h}{\pi B^2} = \frac{\pi b_{h+1}^2 - \pi b_{h}^2 }{\pi B^2} = \frac{b_{h+1}^2 - b_{h}^2 }{B^2}$ (zie boek KÃ©ry & Royle (2015, p. 807)). De logica achter distance sampling is uitgebreider uitgelegd in \@ref(dist-terr).

$$
\begin{aligned}
p_{h} &= \psi_h\int_{b_h}^{b_{h+1}}\text{Pr}(y = 1|r, r \in h)\frac{2r}{b_{h+1}^2 - b_{h}^2}\,dr\\
&= \frac{b_{h+1}^2 - b_{h}^2}{B^2} \int_{b_h}^{b_{h+1}}\frac{2r}{b_{h+1}^2 - b_{h}^2} \exp{\left( -\frac{r^2}{2\sigma^2} \right)}\,dr\\
&= \frac{b_{h+1}^2 - b_{h}^2}{B^2} \frac{2}{b_{h+1}^2 - b_{h}^2}\int_{b_h}^{b_{h+1}}r\exp{\left( -\frac{r^2}{2\sigma^2} \right)}\,dr\\
&= \frac{2}{B^2} (-\sigma^2)\exp{\left( -\frac{r^2}{2\sigma^2} \right)}\Bigg|_{b_h}^{b_{h+1}}\\
&= \frac{-2\sigma^2}{B^2} \left(\exp{\left( -\frac{b_{h+1}^2}{2\sigma^2}\right)} - \exp{\left( -\frac{b_h^2}{2\sigma^2}\right)}\right)\\
&= \frac{2\sigma^2}{B^2} \left(\exp{\left( -\frac{b_{h}^2}{2\sigma^2}\right)} - \exp{\left( -\frac{b_{h+1}^2}{2\sigma^2}\right)}\right)
\end{aligned}
$$

Zodat 

$$
\begin{aligned}
\log{(p_{h})} &= \log{(2)} + 2\log{(\sigma)} - 2\log{(B)} + \log{\left(\exp{\left( -\frac{b_{h}^2}{2\sigma^2}\right)} - \exp{\left( -\frac{b_{h+1}^2}{2\sigma^2}\right)}\right)}\\
&= \log{(2)} + 2\log{(\sigma)} - 2\log{(B)} + \log{\left(\exp{\left( -\frac{b_{h}^2}{2\exp{(2\log{(\sigma)})}}\right)} - \exp{\left( -\frac{b_{h+1}^2}{2\exp{(2\log{(\sigma)})}}\right)}\right)}
\end{aligned}
$$

en dan is $\log{(p)} = \log{\left( \sum_{h = 1}^H \exp{(p_h)} \right)}$

Nu volgt het aantal waargenomen individuen $y_{i,.}$ in plot $i$ voor plots $i = 1, ..., n_{plot}$ de Poisson verdeling, het aantal waargenomen individuen $y_{i,h}$ in afstandscategorie $h$ een multinomiale verdeling en het aantal niet-gedetecteerde dieren $m_{i}$ plot $i$ de Poisson verdeling volgens:

$$
\begin{aligned}
y_{i,.} &\sim \text{Poisson}\left(\lambda_i\sum_{h = 1}^H p_h \right)\\
y_{i,1:H} &\sim \text{Multinomial}(p_{1:H})\\
m_{i} &\sim \text{Poisson}\left(\lambda_i \left(1 - \sum_{h = 1}^H p_h \right) \right)
\end{aligned}
$$

Zodat we de abundantie $N_i$ in plot $i$ kunnen bereken als $N_i = y_{i,.} + m_i$

**Data voorbereiden en model fitten**

Deze werkwijze wordt in een .stan-file geplaatst. 

```{r}
# Hoeveel plots
n_site <- length(unique(gele_kwik_2022_ds$Sample.Label))

# Aantal afstandscategoriÃ«n en cut-offs
n_distance_bins <- 3
max_distance <- 300
bin_breakpoints <- seq(0, max_distance, length.out = n_distance_bins + 1)

# Matrix met aantal observaties per afstandscategorie
y <- gele_kwik_2022_ds %>% mutate(dist_bin = case_when(
  between(distance, 0, 100) ~ 1,
  between(distance, 100, 200) ~ 2,
  between(distance, 200, 300) ~ 3
  )) %>%
  group_by(dist_bin, Sample.Label) %>%
  summarise(aantal = sum(size)) %>%
  pivot_wider(names_from = dist_bin, values_from = aantal) %>%
  select(-c(Sample.Label, `NA`)) %>%
  mutate(`1` = replace_na(`1`, 0),
         `2` = replace_na(`2`, 0),
         `3` = replace_na(`3`, 0)) %>%
  as.matrix()

# Aantal observaties per plot
n_obs <- rowSums(y)

# Sla data op voor model te fitten met STAN
stan_d <- list(
  n_site = n_site,
  n_distance_bins = n_distance_bins,
  bin_breakpoints = bin_breakpoints,
  y = y,
  n_obs = n_obs
)

# Retrieve stan model
path_stan_distance <- paste(stan_models, "distance_sampling.stan", sep = "/")

# Fit model
stan_dist <- stan(path_stan_distance, data = stan_d, iter = niter, 
                  warmup = burnin, chains = nchains, cores = nparallel, 
                  seed = 1235)

# Check convergence first 10 parameters
traceplot(stan_dist)
```


**Resultaten**

De resultaten van de algemene parameters:

```{r}
summary(stan_dist, pars = stan_dist@model_pars[1:4], 
        probs = c(0.025, 0.50, 0.975))$summary %>%
  kable(digits = 4)
```

We sommeren het gemiddeld aantal voorspelde dieren per regio om tot een totaal te komen per regio. 

```{r}
gele_kwik_2022_ds %>% mutate(dist_bin = case_when(
  between(distance, 0, 100) ~ 1,
  between(distance, 100, 200) ~ 2,
  between(distance, 200, 300) ~ 3
  )) %>%
  group_by(dist_bin, Sample.Label) %>%
  summarise(aantal = sum(size)) %>%
  pivot_wider(names_from = dist_bin, values_from = aantal) %>%
  select(-c(`1`, `2`, `3`, `NA`)) %>%
  cbind(predicted = summary(stan_dist, pars = c("n"))$summary[, "mean"]) %>%
  as_tibble() %>%
  full_join(design2022, by = c("Sample.Label" = "plotnaam")) %>%
  group_by(regio ) %>%
  summarise(aantal = sum(predicted))
```

Dit model voorspelt gemiddeld gezien in totaal `r sum(summary(stan_dist, pars = c("n"))$summary[, "mean"])` individuen in het totale studiegebied en een gemiddelde detectiekans van `r exp(sum(summary(stan_dist, pars = c("log_p"))$summary[, "mean"]))`. Wanneer we dit vergelijken met het **Distance** model waarbij we dezelfde breakpoints gebruikten, ook een half-normal functie gebruikten en zonder covariaten, dan zien we gelijkaardige estimates:

```{r}
summary(dsmodelhn2_binned$ddf)
```

**Discussie**

Uitbreidingen:

- Model met Hazard-rate functie 
- Model die ineens schattingen voor de regio's en het totale studiegebied geeft zodat we ook onzekerheid hebben
- Covariaten toevoegen distance functie
    - model $\sigma$ in functie van covariaten
- Covariaten toevoegen abundantieschatting
    - model $\lambda$ in functie van covariaten
- Vergelijk verschillende modellen o.b.v. DIC, WAIC ...
- Priors bekijken

Opmerkingen:
KÃ©ry and Royle (2015, p. 816): *When you write a paper that uses distance sampling with binned data, one criticism raised by a referee undoubtedly will be that it would be better to use a continuous data model instead of an âapproximation.â However, both the continuous distance model and the model for binned data are mere approximations to the actual data-generating process, which we don't know.*  
We zagen voordien al dat gecategoriseerde afstanden een gelijkaardige oplossing gaven als een continu model. Wel is het allicht veiliger om meer categoriÃ«n te nemen.


### inlabru package {#inlabru}

**Op verkenning**

Het ziet er naar uit dat distance sampling enkel met een mesh kan. Onduidelijk.

Handige links:  
https://inlabru-org.github.io/inlabru/articles/web/2d_lgcp_distancesampling.html  
https://rpubs.com/jafet089/886687  
https://inbo.github.io/tutorials/tags/inla/  


## Opdelen in territoria{#territoria}

**Op verkenning**

Het aantal koppels wordt bepaald o.b.v.:

1. Uitsluitende waarnemingen  
Waarnemingen tijdens Ã©Ã©nzelfde telling worden met volledige zekerheid als verschillende dieren beschouwd. Wij beschouwen vier telrondes.

2. Clustering op basis van fusieafstand  
Waarnemingen gedurende verschillende tellingen maar binnen een bepaalde geografische afstand van elkaar (= fusieafstand) worden geclusterd. We gaan er dan van uit dat dit hetzelfde dier was.

Handige links:  
https://docs.google.com/presentation/d/1ZdNfml7MuQ-zM6OWXjE-w7J-x8uij5-Rzn0WKwHXcfc/edit#slide=id.p  
https://github.com/inbo/territoria  

Deze strategie werkt enkel voor honkvaste soorten! Bovendien is de keuze van de fusieafstand belangrijk. Deze kan gebaseerd worden op basis van de data en/of literatuur. De volgende figuur geeft de afstanden weer tussen verschillende koppels binnen dezelfde telling (dus zelfde plot in zelfde telperiode). Dit kan echter een onderschatting geven aangezien onze tellingen zich tot cirkels met straal 300 m beperken. We weten niet of individuen op afstand > 600 m dezelfde zijn. Bovendien kunnen plots overlappen of < 600 m van elkaar verwijderd zijn. We verwachten dat dit echter in dit geval geen grote verschillen zal meebrengen voor deze exploratieve figuur.

(geen goede code, package gebruiken?: https://cran.r-project.org/web/packages/nngeo/index.html)

```{r broed-afstanden}
# Selecteer tellingen van Gele kwikstaart in 2022 in de twee regios
# met broedcode > 0 en binnen telrondes, we behouden de geometrie
gele_kwik_2022_territoria <- mas_clean %>%
  filter(naam == "Gele Kwikstaart", jaar == 2022, 
         !is.na(periode_in_jaar), wrntype > 0L) %>%  
  inner_join(design2022, by = "plotnaam") # Moeren en Leemstreek

# Selecteer coÃ¶rdinaten van broedkoppels waarvan er > 1 per telling
# (zelfde plot zelfde telperiode) werden gezien
broedkoppels <- gele_kwik_2022_territoria %>% 
  group_by(plotnaam, periode_in_jaar) %>%
  mutate(group_id = cur_group_id()) %>% 
  expand(nesting(group_id), nesting(group_id2 = group_id)) %>%
  filter(st_geometry_type(geom) == "MULTIPOINT") %>%
  st_cast(to = "POINT")

# Bereken paarsgewijze afstanden van broedkoppels per telling 
# (zelfde plot zelfde telperiode)
dst <- c()
for (group in broedkoppels$group_id) {
  df <- broedkoppels %>% filter(group_id == group)
  dst <- c(dst, st_distance(df))
}

# Visualiseer in histogram (filter 0 m eruit)
plot_dist_terr <- dst %>% as_tibble() %>% 
  filter(value != 0) %>%
  ggplot() +
    geom_histogram(aes(x = value, y = ..density..), fill = "yellow", 
                   colour = "black", binwidth = 5, alpha = 0.5) +
    labs(x = "Kleinste afstand tot een ander koppel in dezelfde telling (m)") +
    geom_vline(xintercept = mean(dst[dst != 0]), colour = "darkgreen", 
               size = 1.2) + 
    geom_vline(xintercept = quantile(dst[dst != 0], probs = c(0.25, 0.5, 0.75)), 
               colour = "darkblue", size = 1.2) +
    geom_density(aes(x = value, y = ..density..), size = 1)
plot_dist_terr
```

Blauw: Q1-Q3. Groen: gemiddelde.

We zullen er echter initieel voor kiezen om diameter van de telcirkel (600 m) als fusieafstand te nemen. We vermoeden dat dit een iets lager aantal koppels zal opleveren dan de maxima te nemen over de telperiodes indien de telcirkels overlappen of op minder dan 600 m verwijderd zijn van elkaar. Bovendien lijkt het een elegante manier om de territoriastrategie toe te passen op ons design.

**Data voorbereiden**

We hebben voor elke waarneming hun `x`- en `y`-coÃ¶rdinaten nodig in een geprojecteerd coÃ¶rdinatensysteem. `survey` is een geheel getal id voor elke telling. Een survey is dus een unieke combinatie van een plot en een telperiode. `status` is een geheel getal dat de broedcode aangeeft. Een hogere waarde veronderstelt meer zekerheid over een broedgeval. `id` is een unieke id voor iedere observatie

```{r data-prep-territoria}
# Voorbereiden dataframe
df_territoria <- gele_kwik_2022_territoria %>% 
  st_drop_geometry() %>%
  group_by(plotnaam, periode_in_jaar) %>%
  mutate(survey = cur_group_id(),
         status = as.integer(wrntype)) %>%
  ungroup() %>%
  rename(x = x_coord, y = y_coord) %>%
  select(oid, survey, status, x, y, aantal)

# Dupliceer rijen volgens aantal (elke rij is 1 individu)
df_territoria <- 
  tibble(
    df_territoria[rep(seq_len(dim(df_territoria)[1]), 
                  df_territoria$aantal), , 
                  drop = FALSE], 
    row.names = NULL
  ) %>%
  mutate(aantal = 1)

# Gedupliceerde rijen hebben zelfde oid --> nieuw id maken voor elke waarneming
df_territoria <- df_territoria %>% mutate(id = row_number())
```

Zodra we een dataframe met de waarnemingen hebben, maken we verbinding met een SQLite-database en importeren de waarnemingen. Deze kent elke waarneming toe aan een eigen cluster.

```{r SQLite-territoria}
set.seed(20221103)

conn <- connect_db()
import_observations(observations = df_territoria, conn = conn, max_dist = 600)
```

Vervolgens moeten we de afstandsmatrix berekenen. Dit is niet de volledige afstandsmatrix. We laten alle irrelevante afstanden weg, b.v. tussen waarnemingen van dezelfde telling of met een afstand groter dan tweemaal de maximale clusterafstand.

```{r distmatrix-territoria}
distance_matrix(conn = conn, max_dist = 600)
```

**Clusteren met territoria**

Nu kunnen we beginnen met het clusteren. De clustering houdt rekening met alle waarnemingen met een broedcode hoger dan of gelijk aan de ingestelde broedcode. Herhaal de clustering voor elk broedcodeniveau. Merk op dat het overslaan van niveaus impliceert dat we ze combineren met het lagere niveau.

```{r cluster-territoria}
# Broedcodes
broedcodes <- sort(unique(df_territoria$status))

# Cluster van meest zekere broedcode naar minder zeker
result <- vector(mode = "list", length = length(broedcodes))
for (broedcode in rev(broedcodes)) {
  print(paste0("Clusteren broedcode ", broedcode))
  cluster_observation(conn = conn, status = broedcode, max_dist = 600)
  result[[broedcode]] <- get_cluster(conn = conn)
}
dbDisconnect(conn = conn)

# voeg clusternummer toe aan de dataset
df_territoria$cluster <- result[[1]]$observations$cluster
```

**Resultaten en visualisatie**

In totaal hadden we `r nrow(result[[1]]$observations)` observaties (waarneming van een bepaald individu in een plot in een bepaalde telperiode). Nu hebben we `r nrow(result[[1]]$cluster)` clusters (= broedparen).

```{r visualisatie-territoria}
# Hoeveel plots per regio
plots_per_regio <- gele_kwik_2022 %>% 
                     group_by(regio) %>% 
                     summarise(n_plots = n_distinct(plotnaam), .groups = "drop")

territoria_per_plot <- df_territoria %>% 
  
  # Join om regio's te krijgen
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(cluster, regio) %>%
  
  # Voeg aantal plots per regio toe en bereken aantal clusters per plots
  full_join(plots_per_regio, by = "regio") %>%
  group_by(regio, n_plots) %>%
  summarise(broedparen = n_distinct(cluster), .groups = "drop") %>%
  mutate(Estimate = broedparen / n_plots,
         categorie = "territoria")
  
# Visualiseer
territoria_per_plot %>% 
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_bar(aes(fill = regio), stat = "identity") + 
    scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
         name = "Aantal broedparen Gele kwikstaart per 100 ha")) +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart per plot",
         title = "Aantal territoria") +
    theme(legend.position = "")
```

We vergelijken met de vorige resultaten. Ook berekenen we het relatief aantal broedparen op basis van het gemiddeld en maximum aantal per plot over de telperiodes. Hierbij is ook met absensies rekening gehouden (maakt voor maximum niet uit).

```{r comparison-territoria, fig.height=10}
plot_terr <- gele_kwik_2022 %>%
  st_drop_geometry() %>%
  
  # Bepaal voor elke plot het gemiddeld aantal individuen en maximum over
  # de telperiodes
  group_by(plotnaam, periode_in_jaar) %>%
  summarise(totaal = sum(aantal), .groups = "drop_last") %>%
  summarise(gemiddelde = mean(totaal),
            maximum = max(totaal),
            .groups = "drop") %>%
  
  # Join om regio's te krijgen, bereken dan het totaal aantal individuen over 
  # alle plots (som)
  inner_join(design2022, by = "plotnaam") %>%
  select(plotnaam, gemiddelde, maximum, regio) %>%
  group_by(regio) %>%
  summarise(tot_gemiddelde = sum(gemiddelde),
            tot_max = sum(maximum)) %>% 
  
  # Deel door aantal plots om aantal broedkoppels per plot te krijgen
  full_join(plots_per_regio, by = "regio") %>%
  mutate(tot_gemiddelde_plots = tot_gemiddelde / n_plots,
         tot_max_plots = tot_max / n_plots) %>%
  pivot_longer(cols = c("tot_gemiddelde_plots", "tot_max_plots"), 
               names_to = "categorie", values_to = "Estimate") %>%
  
  # Voeg territoria data toe
  select(regio, Estimate, categorie) %>%
  rbind(territoria_per_plot[, -c(2, 3)]) %>%
  
  # Visualiseer
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_bar(aes(fill = regio), stat = "identity") + 
    scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
         name = "Aantal broedparen Gele kwikstaart per 100 ha")) +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart per plot") +
    theme(legend.position = "") +
    facet_wrap(~categorie, labeller = labeller(
      categorie = c(
        "tot_gemiddelde_plots" = "Gemiddeld aantal broedparen per plot",
        "tot_max_plots" = "Maximum aantal broedparen per plot",
        "territoria" = "Aantal territoria")
      ))

grid.arrange(GLMM_model, dist_model_hr8, plot_terr, 
             layout_matrix = rbind(c(1, 2), c(3)))
```

**Discussie**

Dit is toch iets lager aantal dan verwacht (vergelijk met maximum). We verkennen enkele clusters. Vanwaar komen de eerste drie clusters bijvoorbeeld? Deze clusters vormen steeds binnen een plot (zoals verwacht want als fusieafstand namen we de diameter van de telcirkel). Telkens werd een individu gezien in verschillende telkperiodes, dus deze zijn geclusterd.

```{r table-territoria-clusters}
df_territoria %>%
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(oid, cluster, plotnaam, periode_in_jaar, regio) %>%
  filter(cluster %in% sort(unique(df_territoria$cluster))[1:3]) %>%
  arrange(cluster, plotnaam, periode_in_jaar) %>%
  kable()
```

Hoeveel territoria in eerste drie plots? In DM_1037.1 werd telkens 1 individu gezien in elke telperiode. Omdat het binnen de fusieafstand is worden deze waarnemingen geclusterd. In plots DM_1012.6 en DM_1024.10 werden in telperiode R2 twee individuen gezien waardoor er twee clusters zijn. Waarnemingen van andere telperiodes worden geclusterd met het eerste individu.

```{r table-territoria-plots}
df_territoria %>%
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(oid, cluster, plotnaam, periode_in_jaar, regio) %>%
  filter(plotnaam %in% 
           sort(unique(gele_kwik_2022_territoria$plotnaam))[1:3]) %>%
  arrange(cluster, plotnaam, periode_in_jaar) %>%
  kable()
```

Op basis van deze gegevens zouden we een gelijkaardig aantal als bij de maxima verwachten. De analyses zijn wel verlopen zoals verwacht. Zijn er telcirkels die overlappen of die dicht bij elkaar liggen? Met andere woorden, zijn er clusters die in verschillende plots zijn gezien? De twee waarnemingen in cluster 11 bijvoorbeeld bevinden zich in plots DM_222.6 en VL0070 op 488 m van elkaar, maar werden wel door dezelfde waarnemer (JJNN16) gezien op dezelfde dag (2022-06-02). Kunnen we er dan toch van uit gaan dat dit twee verschillende individuen zijn? Nee want niet op zelfde moment (telling) gezien. We zullen dus de cluster surveys niet minder strikt nemen volgens datum en waarnemer in plaats van plot en telperiode. 

```{r overlap-plots}
# Vind clusters met meerdere plots
multi_clust <- df_territoria %>%
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(oid, cluster, plotnaam, regio, periode_in_jaar) %>%
  
  # Aantal plots per cluster
  group_by(cluster) %>%
  summarise(n_plots = n_distinct(plotnaam)) %>%
  
  # Clusters met meer dan 1 plot
  filter(n_plots > 1) %>%
  pull(cluster)

# Tabel
df_territoria %>%
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(oid, cluster, plotnaam, periode_in_jaar, regio) %>%
  filter(cluster %in% multi_clust) %>%
  arrange(regio, cluster, plotnaam, periode_in_jaar) %>%
  kable()
```

Er is dus toch vrij veel overlap van plots (binnen 600 m). Dat verklaart waarom het aantal territoria iets lager is dan het aantal op basis van maxima per plot over de telperiodes. We kozen voor 600 m op basis van ons studiedesign, nl. de diameter van de telcirkel. Omdat er overlap is tussen plots op deze afstand krijgt deze arbitraire afstand nu plots een biologische mening (territoriumafstand Gele kwikstaart op 600 m, logisch?). Dat was niet de bedoeling. Wat we wel kunnen doen is een kleinere fusieafstand nemen met biologische betekenis.

**Kleinere fusieafstand**

```{r pieken-scenario2}
# Extract pieken
hist_piek <- ggplot_build(plot_dist_terr)$data[[1]] %>% 
  filter(y == max(y)) %>% 
  pull(x)
dens_piek <- ggplot_build(plot_dist_terr)$data[[4]] %>% 
  filter(y == max(y)) %>% 
  pull(x)
```

De top van de densiteitscurve van de koppelafstanden lag op `r round(dens_piek, digits = 2)` m, de top van de histogram op `r hist_piek` m, de mediaan op `r round(median(dst[dst != 0]), digits = 2)` m en het gemiddelde op `r round(mean(dst[dst != 0]), digits = 2)` m. Om conservatief te blijven gaan we hier verder met het gemiddelde.

```{r territoria-scenario2}
# Set-up
set.seed(20221104)
fusie_dist <- mean(dst[dst != 0])

# Connect SQLite database en importeer observaties
conn2 <- connect_db()
import_observations(observations = df_territoria, conn = conn2, 
                    max_dist = fusie_dist)

# Bereken distance matrix
distance_matrix(conn = conn2, max_dist = fusie_dist)

# Cluster van meest zekere broedcode naar minder zeker
result2 <- vector(mode = "list", length = length(broedcodes))
for (broedcode in rev(broedcodes)) {
  print(paste0("Clusteren broedcode ", broedcode))
  cluster_observation(conn = conn2, status = broedcode, 
                      max_dist = fusie_dist)
  result2[[broedcode]] <- get_cluster(conn = conn2)
}
dbDisconnect(conn = conn2)

# voeg clusternummer toe aan de dataset
df_territoria2 <- df_territoria
df_territoria2$cluster <- result2[[1]]$observations$cluster
```

Met de grotere fusieafstand van 600m hadden we `r nrow(result[[1]]$cluster)` clusters (= broedparen), nu hebben we met fusieafstand `r round(fusie_dist, digits = 2)` m `r nrow(result2[[1]]$cluster)` clusters.

```{r comparison-territoria-scenario2, fig.height=10}
territoria_per_plot2 <- df_territoria2 %>% 
  
  # Join om regio's te krijgen
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(cluster, regio) %>%
  
  # Voeg aantal plots per regio toe en bereken aantal clusters per plots
  full_join(plots_per_regio, by = "regio") %>%
  group_by(regio, n_plots) %>%
  summarise(broedparen = n_distinct(cluster), .groups = "drop") %>%
  mutate(Estimate = broedparen / n_plots,
         categorie = "territoria")

plot_terr2 <- gele_kwik_2022 %>%
  st_drop_geometry() %>%
  
  # Bepaal voor elke plot het gemiddeld aantal individuen en maximum over
  # de telperiodes
  group_by(plotnaam, periode_in_jaar) %>%
  summarise(totaal = sum(aantal), .groups = "drop_last") %>%
  summarise(gemiddelde = mean(totaal),
            maximum = max(totaal),
            .groups = "drop") %>%
  
  # Join om regio's te krijgen, bereken dan het totaal aantal individuen over 
  # alle plots (som)
  inner_join(design2022, by = "plotnaam") %>%
  select(plotnaam, gemiddelde, maximum, regio) %>%
  group_by(regio) %>%
  summarise(tot_gemiddelde = sum(gemiddelde),
            tot_max = sum(maximum)) %>% 
  
  # Deel door aantal plots om aantal broedkoppels per plot te krijgen
  full_join(plots_per_regio, by = "regio") %>%
  mutate(tot_gemiddelde_plots = tot_gemiddelde / n_plots,
         tot_max_plots = tot_max / n_plots) %>%
  pivot_longer(cols = c("tot_gemiddelde_plots", "tot_max_plots"), 
               names_to = "categorie", values_to = "Estimate") %>%
  
  # Voeg territoria data toe
  select(regio, Estimate, categorie) %>%
  rbind(territoria_per_plot2[, -c(2, 3)]) %>%
  
  # Visualiseer
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_bar(aes(fill = regio), stat = "identity") + 
    scale_y_continuous(sec.axis = sec_axis( ~. / cirkelopp * 1e6, 
         name = "Aantal broedparen Gele kwikstaart per 100 ha")) +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart per plot") +
    theme(legend.position = "") +
    facet_wrap(~categorie, labeller = labeller(
      categorie = c(
        "tot_gemiddelde_plots" = "Gemiddeld aantal broedparen per plot",
        "tot_max_plots" = "Maximum aantal broedparen per plot",
        "territoria" = "Aantal territoria")
      ))

grid.arrange(GLMM_model, dist_model_hr8, plot_terr2, 
             layout_matrix = rbind(c(1, 2), c(3)))
```

Nu zien we dat het aantal territoria (broedparen) hoger zijn dan de maxima. Dat komt omdat nu ook binnen plots clusters worden gevormd indien waarnemingen ver genoeg uit elkaar liggen en niet in dezelfde telperiode zijn gedaan.  

Is er ook nog steeds overlap in plots?

```{r overlap-plots-scenario2}
# Vind clusters met meerdere plots
multi_clust2 <- df_territoria2 %>%
  inner_join(gele_kwik_2022_territoria, by = "oid") %>%
  select(oid, cluster, plotnaam, regio, periode_in_jaar) %>%
  
  # Aantal plots per cluster
  group_by(cluster) %>%
  summarise(n_plots = n_distinct(plotnaam)) %>%
  
  # Clusters met meer dan 1 plot
  filter(n_plots > 1) %>%
  pull(cluster)

length(multi_clust2)
```

Geen overlap meer.

**Kunnen we distance sampling toepassen op de clusters?**

- Afstand telpunt tot cluster (centroid) is niet hetzelfde als het gemiddelde van de afstanden van de afzonderlijke waarnemingen tot het telpunt (simulatie in script). Nieuwe afstand berekenen van cluster tot telpunt. Als er overlap van plots is binnen fusieafstand (cluster over verschillende plots) is de vraag wel tot welk telpunt (welke plot) we de afstand nemen (of gewogen gemiddelde, bv 2 waarnemingen uit plot x komen en 1 uit plot y).
- Covariaten moeten herberekend worden indien er overlap van plots is binnen fusieafstand.
- Opgelet bij omzetten data. In **territoria** is elke rij een waarneming van een enkel individu, in **Distance** gaven me in de kolom `size` het aantal aan per waarneming. Nu zal `size` overal 1 zijn. `Region.Label` zal nu ook niet meer de telperiode bevatten ...

```{r, include=FALSE}
# If blue buffer goes through centroid the average distance is the same as mean 
# of distances from points
set.seed(123)

replicate(6, {
  # Simulate points
  points <- data.frame(id = c("X", "Y", "Z", "ref"), x = runif(4), y = runif(4))
  point_sf <- st_as_sf(points, coords = 2:3)
  
  # Add centroid
  point_sf <- point_sf %>% 
    summarise(geometry = st_union(geometry[1:3])) %>%
    st_centroid() %>%
    mutate(id = "centroid") %>%
    select(id, geometry) %>%
    rbind(point_sf) %>%
    mutate(var = c("centroid", rep("point", 3), "ref"))
    
  # Buffer around centroid equal to distance to reference
  # Buffer around reference equal to mean distances from other points
  buffer <- c(st_distance(point_sf[point_sf$id == "centroid", ], 
                   point_sf[point_sf$id == "ref", ]),
                rep(0, 3), 
                mean(c(st_distance(point_sf[point_sf$id == "X", ], 
                       point_sf[point_sf$id == "ref", ]),
                     st_distance(point_sf[point_sf$id == "Y", ], 
                       point_sf[point_sf$id == "ref", ]),
                     st_distance(point_sf[point_sf$id == "Z", ], 
                       point_sf[point_sf$id == "ref", ]))))
  
  point_sf_buffer <- point_sf %>% st_buffer(buffer)
  
  # Plot
  print(ggplot(point_sf_buffer) +
    geom_sf(aes(colour = var), fill = alpha("white", 0)) +
    geom_sf(data = point_sf, aes(colour = var)))
})

# The buffer around the reference point is the mean distance
# It never goes through the centroid
```


## Scenario 1: Distance met territoria{#dist-terr}

In dit scenario clusteren we waarnemingen tot broedparen met **territoria**. Daarna doen we met deze data distance sampling met **Distance**. We beschouwen de eerste stap als data preparatie en de tweede stap de statistische analyse om het aantal broedparen per 100 ha te schatten waarbij we corrigeren voor detectiekans.


### Data voorbereiden

In de output van **territoria** krijgen we de centroide van de clusters (gemiddelde coordinaten van waarnemingen per cluster). Om niet te veel te moeten joinen berekenen we deze coordinaten opnieuw met de **sf** package. We maken een kolom `Sample.Label` met de het id van de plot, `size` is het aantal broedparen per cluster (overal 1), `regio`, `sbp` en `openheid` zijn covariaten, `Effort` is het aantal keer dat een plot is bezocht (overal 1). `Region.Label` is een label voor elke regio (zelfde als `regio`-kolom).

```{r}
# Voeg clusters toe aan presence data
df_dist_terr_presence <- sp::merge(gele_kwik_2022_territoria, df_territoria2, 
                                   by = intersect("oid", "oid")) %>%
  select(plotnaam, cluster, aantal.y, regio, sbp, openheid) %>%
  rename("Sample.Label" = plotnaam, "size" = aantal.y) %>%
  
# Bereken centroide per cluster 
  group_by(cluster) %>%
  mutate(geometry = st_union(geometry)) %>%
  st_centroid() %>%
  ungroup() %>%
  arrange(cluster) %>%
  distinct()

# Inlezen coÃ¶rdinaten telpunt
telpunt_coord <- read_sf(
  here("data/processed/steekproef_piloot_avimap.geojson")
  ) %>%
  select(definitief_punt)

# Bereken afstanden van centroide tot telpunt
df_dist_terr_presence2 <- left_join(df_dist_terr_presence %>% as.data.frame(), 
                            telpunt_coord %>% as.data.frame(), 
                            by = c("Sample.Label" = "definitief_punt")) %>%
  mutate(distance = as.numeric(
    st_distance(
      .data[["geometry.x"]] %>% st_sf(), 
      .data[["geometry.y"]] %>% st_sf(), 
      by_element = TRUE)
    )) %>%
  select(-"geometry.y") %>% 
  rename(geometry = geometry.x) %>%
  st_sf(sf_column_name = "geometry")

# Voeg afwezigheden en sampling effort toe
effort_df <- bezoekenlijst_2022 %>%
  group_by(plotnaam) %>%
  mutate(Effort = 1) %>%
  select(-c(periode_in_jaar, stratum)) %>%
  distinct() %>%
  ungroup()

df_dist_terr <- df_dist_terr_presence2 %>%
  full_join(effort_df, by = c("Sample.Label" = "plotnaam",
                              "regio", "sbp", "openheid")) %>%
  mutate(size = ifelse(is.na(size), 0, size)) %>%

# Voeg Area en Region.Label toe
  full_join(reg_tab, by = "regio") %>%
  mutate(Region.Label = regio)

# Eerste tien rijen van dataset
df_dist_terr
```


### Data exploratie

Samenvattende tabel aantal broedparen per stratum. Area is in kmÂ².

```{r}
df_dist_terr %>%
  st_drop_geometry() %>%
  group_by(regio, sbp, openheid, Area) %>%
  summarise(aantal_broedparen = sum(size)) %>%
  group_by(regio) %>%
  mutate(aantal_broedparen_per_regio = sum(aantal_broedparen)) %>%
  select(-Area, everything(), Area) %>%
  rename(area_per_regio = Area) %>%
  kable()
```

Verdeling van de geregistreerde afstanden:
  
```{r} 
# Tabel
df_dist_terr %>% 
  st_drop_geometry() %>%
  group_by(regio, sbp, openheid) %>%
  summarise(min = min(distance, na.rm = TRUE), 
            mediaan = median(distance, na.rm = TRUE),
            gemiddelde = mean(distance, na.rm = TRUE),
            max = max(distance, na.rm = TRUE),
            varantie = var(distance, na.rm = TRUE)) %>%
  kable(digits = 1)

# Histogram
df_dist_terr %>%
  filter(!is.na(distance)) %>%
  mutate(stratum = paste0(openheid, "\n", sbp, " plan")) %>%
  ggplot() +
    geom_histogram(aes(x = distance, fill = stratum), bins = 30) +
    facet_wrap(~regio) +
    labs(y = "Aantal", x = "Afstand (m)")
```

We zien plots enkele afstanden > 300 m. Dit zou niet mogen kunnen. We kijken even naar clusters die bestaan uit 1 waarneming. Hierbij zijn de coÃ¶rdinaten van de centroide gelijk aan de coÃ¶rdinaten van de originele waarneming.

```{r}
# Dataset met oorspronkelijke afstanden
original_dist <- sp::merge(gele_kwik_2022_territoria, df_territoria2, 
                           by = intersect("oid", "oid")) %>%
  group_by(cluster) %>%
  mutate(n = n()) %>%
  filter(n == 1) %>%
  rename(origi_distance = distance2plot) %>%
  arrange(cluster)

# Welke clusters bestaan uit 1 waarneming?
single_clusts <- original_dist$cluster

# Dataset met herberekende afstanden (centroid tot telpunt)
new_dist <- df_dist_terr %>%
  filter(cluster %in% single_clusts) %>%
  rename(new_distance = distance) %>%
  arrange(cluster)

# Join oorspronkelijke en nieuwe datasets
full_df <- original_dist %>% 
  st_join(new_dist)

# Zoek punten waarbij oorspronkelijke en nieuwe afstanden niet overeenkomen
intersect <- full_df %>%
  filter(!(origi_distance %in% c(floor(new_distance), ceiling(new_distance))))

# Vergelijk oorspronkelijke en nieuwe afstanden (mismatches in blauw)
full_df %>%
  ggplot(aes(x = origi_distance, y = new_distance)) +
    geom_abline(intercept = 0, slope = 1, colour = "red") + 
    geom_point() +
    geom_point(data = intersect, aes(x = origi_distance, y = new_distance), 
               colour = "blue")
```

We zien dat voor sommige clusters de herberekende afstanden niet gelijk zijn aan de afstanden in de originele dataset (kolom `distance2plot`). Waarom?

```{r}
intersect %>% 
  group_by(regio.x, sbp.x, openheid.x) %>%
  st_drop_geometry() %>%
  summarise(aantal_broedparen = sum(aantal.x)) %>%
  group_by(regio.x) %>%
  mutate(aantal_broedparen_per_regio = sum(aantal_broedparen)) %>%
  kable()
```

We zien geen verband met regio, sbp of openheid. We plotten enkele clusters die mismatchen. In blauw zien we dat de herberekende afstanden voor elke cluster mooi door het telpunt gaan. Dit is niet voor de originele afstanden (rood):

```{r}
plot_circles <- function(plot) {
  
  data_origi <- original_dist %>% 
    filter(plotnaam == plot) 
  buffer_origi <- data_origi %>% 
    st_buffer(data_origi$origi_distance)
  
  data_new <- new_dist %>% 
   filter(Sample.Label == plot)
  buffer_new <- data_new %>% 
    st_buffer(data_new$new_distance)
  
  ggplot() +
    geom_sf(data = data_origi,
            colour = "red", size = 5) +
    geom_sf(data = buffer_origi,
            colour = "red", fill = alpha("white", 0)) +
    geom_sf_text(data = data_origi,
                 label = "original distance", colour = "red", 
                 nudge_x = c(0, 0),
                 nudge_y = c(50, 50)) +
    
    geom_sf(data = data_new,
            colour = "blue", size = 3) +
    geom_sf(data = buffer_new,
            colour = "blue", fill = alpha("white", 0)) +
    geom_sf_text(data = data_new,
            label = "new distance", colour = "blue", 
            nudge_x = c(0, 0),
            nudge_y = c(75, 75)) +
    
    geom_sf(data = telpunt_coord %>% 
              filter(definitief_punt == plot),
            colour = "darkgreen", size = 5) +
    geom_sf(data = telpunt_coord %>% 
              filter(definitief_punt == plot) %>% 
              st_buffer(300),
          colour = "darkgreen", fill = alpha("white", 0)) +
    geom_sf_text(data = telpunt_coord %>% 
              filter(definitief_punt == plot),
            label = "telpunt (300 m buffer)", colour = "darkgreen", 
            nudge_x = 100,
            nudge_y = -10) +
    
    coord_sf(datum = proj_crs) +
    labs(title = paste0("plot: ", plot))
}


plot_circles("DM_222.6")
plot_circles("DM_137.2")
plot_circles("Ol_4680")
```

We zien ook geen spatiale trend in de waarnemingen waarvoor we een mismatch hebben:

```{r}
intersect_ids <- intersect$cluster.x
full_df <- full_df %>% 
  mutate(correct = ifelse(cluster.x %in% intersect_ids, "fout", "correct"))

mapview(telpunt_coord, legend = FALSE, col.regions = "green") +
mapview(telpunt_coord %>% st_buffer(300), 
        legend = FALSE, col.regions = "green", alpha.region = 0.1) +
mapview(full_df, zcol = "correct")
```

**Conclusie:** We hebben de exacte coÃ¶rdinaten van de clusters en de telpunten dus we gaan er van uit dat de herberekende afstanden correct zijn. Voorlopig hebben we geen verklaring. Bij SOVON terugkoppelen hoe die afstanden worden berekend (automatisch in app?). Een mogelijkheid is wel dat de teller niet exact op het telpunt staat wanneer hij waarnemingen ingeeft waardoor de berekende afstanden in de app nu niet overeenkomen met de afstand tussen het theoretische telpunt en de waarnemingen. Soms zijn de mismatches wel groot (> 100 m), en vele gevallen is er geen mismatch. De mismatches zijn ook aanwezig bij verschillende tellers. Het blijft dus onduidelijk wat er aan de hand is.


### Model fit en selectie

We maken een model voor de probabiliteit dat een Gele kwikstaart wordt gedetecteerd gegeven we de afstand tot het individu weten. Dit model is de detectiefunctie en wordt genoteerd als $g(r;\boldsymbol \theta)$ met $r$ de radiale afstand van waarneming tot teller/telpunt en $\boldsymbol \theta$ een vector van parameters die geschat moeten worden. Het doel is de gemiddelde kans op detectie ($p$) te bepalen (gemiddelde in de zin van een gemiddelde over afstand van 0 tot afknotafstand $w$).

$$
p = \int_0^w\frac{2r}{w^2}g(r;\boldsymbol \theta)\,dr
$$

$p$ is dus de oppervlakte onder de detectiecurve. De volgende figuur toont een fictief voorbeeld van een histogram met afstanden van 0 tot 300 meter ($w = 300$). Het is duidelijk dat de er op grotere afstand minder waarnemingen zijn. Moest dit niet het geval zijn, zouden de afstanden uniform verdeeld zijn zoals de blauwe box. Alles zou gezien zijn en $p = 1$. Dit is hier dus niet het geval. De rode curve is een half-normale detectiecurve gefit op de data. De oppervlakte onder de curve binnen de box is de gemiddelde detectiekans (de geschatte fractie dieren die gezien zijn). De oppervlakte boven de curve binnen de box de geschatte fractie dieren die gemist zijn. Als we de gemiddelde detectiekans weten, kunnen we dus eenvoudig berekenen hoeveel dieren we verwachten als we uitgaan van een uniforme verdeling van dieren over de telcirkel. We controleren er dus voor dat het moeilijker is om dieren te detecteren op grotere afstand, terwijl we er van uitgaan dat er evenveel zitten op grotere als op kleinere afstanden.

```{r}
set.seed(20221121)
tibble(distances = rnorm(500, sd = 120)) %>%
  mutate(distances = abs(distances)) %>%
  ggplot(aes(x = distances)) +
    geom_rect(aes(xmin = 0, xmax = 300, ymin = 0, ymax = dnorm(0, sd = 120)), 
                  colour = "blue", size = 1, fill = "aliceblue", alpha = 0.05) +
    geom_histogram(aes(y = ..density.. / 2), breaks = seq(0, 300, by = 25), 
                   fill = "white", colour = "black") +
    stat_function(data = tibble(distances = rnorm(500, sd = 120)) %>%
                    mutate(distances = abs(distances)),
                  aes(x =  distances), fun = dnorm, n = 1000, 
                  args = list(sd = 120), colour = "red", size = 1) +
    geom_rect(aes(xmin = 0, xmax = 300, ymin = 0, ymax = dnorm(0, sd = 120)), 
              colour = "blue", size = 1, fill = alpha("white", 0)) +
    labs(x = "Afstand (m)", y = "")
```

We gaan opnieuw tewerk zoals in subsectie \@ref(Distance). We fitten 3 verschillende detectiefuncties die we laten afhangen van covariaten regio, sbp en openheid. De detectiekans word dan berekend conditioneel aan de waargenomen waarden van de covariaten.

$$
p(\mathbf{z_i}) = \int_0^w\frac{2r}{w^2}g(r, \mathbf{z_i};\boldsymbol \theta)\,dr
$$

Met $\mathbf{z_i}$ een vector van $J$ (hier $J=3$) covariaten geassocieerd met observatie $i$. We beschouwen ook interacties. De interactie tussen regio en openheid kan niet gefit worden (geen HOL in De Moeren). Voor de uniforme verdeling kunnen geen covariaten worden toegevoegd. Bij deze verdeling neemt detectiekans niet af en heb je alle individuen gezien.

- Fitting uniform key function

$$
g(r;\boldsymbol \theta) = 1 / w
$$

```{r}
ds_scen1_unif1 <- ds(data = df_dist_terr, key = "unif", truncation = 300, 
                     transect = "point", dht_group = FALSE,
                     convert_units = conversion_factor)
```

- Fitting half-normal key function

$$
g(r, \mathbf{z};\boldsymbol \theta) = \exp{\left( -\frac{r^2}{2\sigma(\mathbf{z})^2} \right)}
$$
met scale parameter

$$
\sigma(\mathbf{z}) = \exp{\left( \beta_0 + \sum_{j = 1}^{J} \beta_j z_j \right)}
$$

```{r}
# Null model
ds_scen1_hn1 <- ds(data = df_dist_terr, key = "hn", truncation = 300, 
                   transect = "point", dht_group = FALSE,
                   convert_units = conversion_factor)

# Single covariate
ds_scen1_hn2 <- ds(data = df_dist_terr, key = "hn", formula = ~ regio,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn3 <- ds(data = df_dist_terr, key = "hn", formula = ~ sbp,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn4 <- ds(data = df_dist_terr, key = "hn", formula = ~ openheid,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

# Combination of covariates
ds_scen1_hn5 <- ds(data = df_dist_terr, key = "hn", formula = ~ regio + sbp,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn6 <- ds(data = df_dist_terr, key = "hn", 
                   formula = ~ regio + openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn7 <- ds(data = df_dist_terr, key = "hn", formula = ~ sbp + openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn8 <- ds(data = df_dist_terr, key = "hn", 
                   formula = ~ regio + sbp + openheid,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

# Interactions between covariates
ds_scen1_hn9 <- ds(data = df_dist_terr, key = "hn", formula = ~ regio * sbp,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn10 <- ds(data = df_dist_terr, key = "hn", formula = ~ sbp * openheid,
                    adjustment = NULL, truncation = 300, transect = "point", 
                    dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn11 <- ds(data = df_dist_terr, key = "hn", 
                    formula = ~ regio + sbp * openheid,
                    adjustment = NULL, truncation = 300, transect = "point", 
                    dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hn12 <- ds(data = df_dist_terr, key = "hn", 
                    formula = ~ regio * sbp + openheid,
                    adjustment = NULL, truncation = 300, transect = "point", 
                    dht_group = FALSE, convert_units = conversion_factor)
```

- Fitting hazard-rate key function

$$
g(r, \mathbf{z};\boldsymbol \theta) = 1 - \exp{\left( \left( -\frac{r}{\sigma(\mathbf{z})}\right)^{-b} \right)}
$$
met scale parameter

$$
\sigma(\mathbf{z}) = \exp{\left( \beta_0 + \sum_{j = 1}^{J} \beta_j z_j \right)}
$$

```{r}
# Null model
ds_scen1_hr1 <- ds(data = df_dist_terr, key = "hr", truncation = 300, 
                   transect = "point", dht_group = FALSE,
                   convert_units = conversion_factor)

# Single covariate
ds_scen1_hr2 <- ds(data = df_dist_terr, key = "hr", formula = ~ regio,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr3 <- ds(data = df_dist_terr, key = "hr", formula = ~ sbp,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr4 <- ds(data = df_dist_terr, key = "hr", formula = ~ openheid,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

# Combination of covariates
ds_scen1_hr5 <- ds(data = df_dist_terr, key = "hr", formula = ~ regio + sbp,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr6 <- ds(data = df_dist_terr, key = "hr", 
                   formula = ~ regio + openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr7 <- ds(data = df_dist_terr, key = "hr", formula = ~ sbp + openheid,
                 adjustment = NULL, truncation = 300, transect = "point", 
                 dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr8 <- ds(data = df_dist_terr, key = "hr", 
                   formula = ~ regio + sbp + openheid,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

# Interactions between covariates
ds_scen1_hr9 <- ds(data = df_dist_terr, key = "hr", formula = ~ regio * sbp,
                   adjustment = NULL, truncation = 300, transect = "point", 
                   dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr10 <- ds(data = df_dist_terr, key = "hr", formula = ~ sbp * openheid,
                    adjustment = NULL, truncation = 300, transect = "point", 
                    dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr11 <- ds(data = df_dist_terr, key = "hr", 
                    formula = ~ regio + sbp * openheid,
                    adjustment = NULL, truncation = 300, transect = "point", 
                    dht_group = FALSE, convert_units = conversion_factor)

ds_scen1_hr12 <- ds(data = df_dist_terr, key = "hr", 
                    formula = ~ regio * sbp + openheid,
                    adjustment = NULL, truncation = 300, transect = "point", 
                    dht_group = FALSE, convert_units = conversion_factor)
```

We vergelijken de AIC van de verschillende modellen. Als het verschil tussen AICâs kleiner is dan 2, kiezen we het eenvoudigste van deze modellen. Modellen met vergelijkbare AICâs hebben vergelijkbare geschatte detectiekansen, dus in de praktijk is er weinig verschil in de keuze tussen deze modellen.

```{r}
summarize_ds_models(ds_scen1_unif1, 
                    ds_scen1_hn1, ds_scen1_hn2, ds_scen1_hn3, 
                    ds_scen1_hn4, ds_scen1_hn5, ds_scen1_hn6, ds_scen1_hn7, 
                    ds_scen1_hn8, ds_scen1_hn9, ds_scen1_hn10, ds_scen1_hn11, 
                    ds_scen1_hn12,
                    ds_scen1_hr1, ds_scen1_hr2, ds_scen1_hr3, 
                    ds_scen1_hr4, ds_scen1_hr5, ds_scen1_hr6, ds_scen1_hr7, 
                    ds_scen1_hr8, ds_scen1_hr9, ds_scen1_hr10, ds_scen1_hr11, 
                    ds_scen1_hr12) %>%
  kable()
```

De modellen waarbij de detectiekans afhankelijk is van regio en soortbeschermingsplan scoren het best. 

$$
\sigma(\mathbf{z}) = \exp{\left( \beta_0 + \beta_1 z_{regio} + \beta_2 z_{sbp} \right)}
$$

De gemiddelde detectiekans $\hat{P}_a$ verschilt tussen hazard-ratio en half-normal functies waarbij deze steeds lager is voor half-normal modellen. $\hat{P}_a$ is een samenvattende statistiek die ons een idee geeft van hoe detecteerbaar onze $n$ waargenomen dieren zouden zijn om dezelfde abundantie te schatten als er geen waargenomen covariabelen waren. We bekijken model fit van modellen 6 (half-normal) en 18 (hazard-rate) m.b.v. QQ-plots en probability density function plots. Voor punttransectstudies geven probability density function plots een beter idee van modelfit dan de detectiefunctieplots. Dit komt omdat bij het plotten van de detectiefunctie voor punttransectgegevens, de histogram opnieuw moet worden geschaald om rekening te houden met de geometrie van de punt. Punten op de plot geven de kans op detectie voor elke waarneming aan.

```{r}
# Hazard-rate in functie van regio en sbp
par(mfrow = c(1, 2))

gof_ds(ds_scen1_hr5, main = "ds_scen1_hr5")

plot(ds_scen1_hr5, pdf = FALSE, main = "P(detectie) ~ regio + sbp")

par(mfrow = c(1, 1))
plot(ds_scen1_hr5, pdf = TRUE, 
     main = paste0("ds_scen1_hr5", " - ", "AIC: ",
                   as.character(round(summary(ds_scen1_hr5)$ds$aic, digits = 2))
                   )
     )

# Half-normal in functie van regio en sbp
par(mfrow = c(1, 2))

gof_ds(ds_scen1_hn5, main = "ds_scen1_hn5")

plot(ds_scen1_hn5, pdf = FALSE, main = "P(detectie) ~ regio + sbp")

par(mfrow = c(1, 1))
plot(ds_scen1_hn5, pdf = TRUE, 
     main = paste0("ds_scen1_hn5", " - ", "AIC: ",
                   as.character(round(summary(ds_scen1_hn5)$ds$aic, digits = 2))
                   )
     )
```


### Resultaten en visualisatie

We vergelijken de resultaten van beide modellen.  
  
De coÃ«fficiÃ«nten voor de scale coefficient verschillen lichtjes tussen beide modellen:

```{r}
summary_scen1_hr5 <- summary(ds_scen1_hr5)
summary_scen1_hr5$ds$coeff$key.scale %>%
  kable(digits = 3, caption = "Hazard-rate model")

summary_scen1_hn5 <- summary(ds_scen1_hn5)
summary_scen1_hn5$ds$coeff$key.scale %>%
  kable(digits = 3, caption = "Half-normal model")
```

We hebben de studieregio in 2 strata opgesplits: De Moeren en de Oostelijke leemstreek. Beschouw $A(s)$ de totale oppervlakte van stratum $s$ tot waar we de abundantieschatting willen extrapoleren en $a(s)$ het gesampelde gebied.

$$
a(s) = \pi w^2 T
$$
Met $T$ het aantal plots ($n_p$) vermenigvuldigd met het aantal bezoeken (effort). In ons geval hebben we dus $a(s) = \pi 300^2 n_p 4$. Dan is de geschatte abundantie in het gesampelde gebied voor elk stratum $s$:

$$
\hat{N}_C(s) = \sum_{i=1}^n \frac{c_i(s)}{\hat{p}(\mathbf{z_i})}
$$
Met $c_i(s)$ de clustergrootte in stratum $s$ voor waarneming $i$. In ons geval 1 als de waarneming in het stratum voorkomt en 0 indien niet. De geschatte abundantie in het gesampelde gebied kan dan worden opgeschaald naar de totale oppervlakte van het stratum via:

$$
\hat{N}(s) = \frac{A(s)}{a(s)}\hat{N}_C(s)
$$

De geschatte densiteit is dan $\hat{N}(s) / A(s)$. De abundanties kunnen ook opgeteld worden voor een totale schatting en een totale densiteit door de totale schatting te delen door de totale oppervlakte (som van oppervlaktes per stratum). Voor berekening van de confidence limits zie `?dht`. De confidence limits in de volgende resultaten zijn 95 % confidence intervallen.

Wie zien dat de abundantie- en densiteitsestimates ook licht verschillen tussen de modellen. Het geschatte aantal broedparen en de standard errors van het hazard-rate model zijn telkens lager dan deze van het half-normal model. We zagen inderdaad al dat de detectiekans lager was bij Half-normal modellen. Daardoor zal bij het half-normal model er sterker gecorrigeerd worden voor gemiste individuen en bekomen we een hoger geschatte aantal op het einde.

```{r}
# Vat resultaten Hazard-rate model samen
summary_results_scen1_hr5 <- bind_rows(
  summary_scen1_hr5$dht$clusters$D %>%
    mutate(variable = "density",
           type = "clusters"),
  summary_scen1_hr5$dht$clusters$N %>%
    mutate(variable = "abundance",
           type = "clusters"),
  summary_scen1_hr5$dht$individuals$D %>%
    mutate(variable = "density",
           type = "individuals"),
  summary_scen1_hr5$dht$individuals$N %>%
    mutate(variable = "abundance",
           type = "individuals")
  )

# Vat resultaten Half-normal model samen
summary_results_scen1_hn5 <- bind_rows(
  summary_scen1_hn5$dht$clusters$D %>%
    mutate(variable = "density",
           type = "clusters"),
  summary_scen1_hn5$dht$clusters$N %>%
    mutate(variable = "abundance",
           type = "clusters"),
  summary_scen1_hn5$dht$individuals$D %>%
    mutate(variable = "density",
           type = "individuals"),
  summary_scen1_hn5$dht$individuals$N %>%
    mutate(variable = "abundance",
           type = "individuals")
  )

# Voorbereiding dataframes
df_results_hr5 <- summary_results_scen1_hr5 %>%
  filter(type == "individuals") %>%
  mutate(variable = recode_factor(variable, 
            abundance = "Totaal aantal broedparen Gele kwikstaart",
            density = "Aantal broedparen Gele kwikstaart per 100 ha"),
         regio = ifelse(Label == "Total", "totaal", Label),
         model = "Hazard-rate")

df_results_hn5 <- summary_results_scen1_hn5 %>%
  filter(type == "individuals") %>%
  mutate(variable = recode_factor(variable, 
            abundance = "Totaal aantal broedparen Gele kwikstaart",
            density = "Aantal broedparen Gele kwikstaart per 100 ha"),
         regio = ifelse(Label == "Total", "totaal", Label),
         model = "Half-normal")
```

Tabel:

```{r}
rbind(df_results_hr5, df_results_hn5) %>%
  mutate(betekenis = recode_factor(variable, 
            "Totaal aantal broedparen Gele kwikstaart" = "Totaal aantal broedparen",
            "Aantal broedparen Gele kwikstaart per 100 ha" = "Aantal per 100 ha")) %>%
  select(model, regio, betekenis, Estimate, se, lcl, ucl) %>%
  arrange(model, regio, betekenis) %>%
  kable(digits = 3)
```

Plot:

```{r, fig.width = 8}
rbind(df_results_hr5, df_results_hn5) %>%
  ggplot(aes(x = regio, y = Estimate, colour = model)) + 
    geom_point(position = position_dodge(width = 0.5), size = 4) + 
    geom_errorbar(aes(ymin = lcl, ymax = ucl), width = 0.25,
                  position = position_dodge(width = 0.5)) +
    scale_y_continuous(limits = c(0, NA)) +
    scale_colour_manual(values = c("orange", "purple")) +
    facet_wrap(~variable, scales = "free_y") +
    labs(x = "", y = "", title = "P(detectie) ~ regio + sbp")
```


### Discussie

De volgende figuren tonen het aantal broedparen per 100 ha. Puntschattingen zijn steeds aangegeven; enkel in het geval van distance sampling hebben we confidence limits (95 %). Aantal territoria is berekend als het aantal clusters (via **territoria** package) per circeloppervlakte en dan omgezet naar hectare. Bij distance sampling hebben we ook de clusters gebruikt, maar hebben we rekening gehouden met detectiekans. De schattingen worden dan omgezet naar 100 ha o.b.v. de oppervlakte van de regio's en niet o.b.v. de cirkeloppervlakte. Bij het gemiddelde aantal per plot nemen we som van alle gemiddelde aantallen broedparen per plot waarbij we het gemiddelde nemen over de telperiodes en bij het maximum het maximum aantal over de telperiodes per plot. Daarna wordt dit aantal berekend per circeloppervlakte en dan omgezet naar 100 hectare.

```{r, fig.height=7, fig.width=9}
p1 <- territoria_per_plot2 %>%
  mutate(Estimate = Estimate / cirkelopp * 1e6) %>%
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_bar(aes(fill = regio), stat = "identity") +
    geom_text(aes(label = round(Estimate, digits = 2)), vjust = -0.5,
              colour = "black") +
    scale_y_continuous(limits = c(0, 14)) +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart\nper 100 ha", 
         title = "Aantal territoria") +
  theme(legend.position = "")

p2 <- rbind(df_results_hr5, df_results_hn5) %>%
  filter(variable == "Aantal broedparen Gele kwikstaart per 100 ha",
         regio != "totaal") %>%
  ggplot(aes(x = regio, y = Estimate, colour = model)) + 
    geom_point(position = position_dodge(width = 0.5), size = 4) + 
    geom_text(aes(label = round(Estimate, digits = 2)), 
            position = position_dodge(width = 1.75), vjust = -0.25) +
    geom_errorbar(aes(ymin = lcl, ymax = ucl), width = 0.25,
                  position = position_dodge(width = 0.5)) +
    scale_y_continuous(limits = c(0, 14)) +
    scale_colour_manual(values = c("orange", "purple")) +
    labs(x = "", y = "", title = "P(detectie) ~ regio + sbp")

p3 <- gele_kwik_2022 %>%
  st_drop_geometry() %>%
  
  # Bepaal voor elke plot het gemiddeld aantal individuen en maximum over
  # de telperiodes
  group_by(plotnaam, periode_in_jaar) %>%
  summarise(totaal = sum(aantal), .groups = "drop_last") %>%
  summarise(gemiddelde = mean(totaal),
            maximum = max(totaal),
            .groups = "drop") %>%
  
  # Join om regio's te krijgen, bereken dan het totaal aantal individuen over 
  # alle plots (som)
  inner_join(design2022, by = "plotnaam") %>%
  select(plotnaam, gemiddelde, maximum, regio) %>%
  group_by(regio) %>%
  summarise(tot_gemiddelde = sum(gemiddelde),
            tot_max = sum(maximum)) %>% 
  
  # Deel door aantal plots om aantal broedkoppels per plot te krijgen
  full_join(plots_per_regio, by = "regio") %>%
  mutate(tot_gemiddelde_plots = tot_gemiddelde / n_plots,
         tot_max_plots = tot_max / n_plots) %>%
  pivot_longer(cols = c("tot_gemiddelde_plots", "tot_max_plots"), 
               names_to = "categorie", values_to = "Estimate") %>%
  
  # Reken om naar 100 ha
  mutate(Estimate = Estimate / cirkelopp * 1e6) %>%
  
  # Visualiseer
  ggplot(aes(x = regio, y = Estimate)) + 
    geom_bar(aes(fill = regio), stat = "identity") +
    geom_text(aes(label = round(Estimate, digits = 2)), vjust = -0.5,
            colour = "black") +
    labs(x = "", y = "Aantal broedparen Gele kwikstaart\nper 100 ha") +
    scale_y_continuous(limits = c(0, 4)) +
    theme(legend.position = "") +
    facet_wrap(~categorie, labeller = labeller(
      categorie = c(
        "tot_gemiddelde_plots" = "Gemiddeld aantal broedparen per plot",
        "tot_max_plots" = "Maximum aantal broedparen per plot")
      ))

suppressWarnings({
grid.arrange(p1, p2, p3, layout_matrix = rbind(c(1, 2), c(3)))
})
```



